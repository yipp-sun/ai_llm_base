# Prompt templates: Few shotã€Example selector
## <font style="color:rgb(28, 30, 33);">Few shot(å°‘é‡ç¤ºä¾‹)</font>
### <font style="color:rgb(28, 30, 33);">åˆ›å»ºå°‘é‡ç¤ºä¾‹çš„æ ¼å¼åŒ–ç¨‹åº</font>
<font style="color:rgb(28, 30, 33);">åˆ›å»ºä¸€ä¸ªç®€å•çš„æç¤ºæ¨¡æ¿ï¼Œç”¨äºåœ¨ç”Ÿæˆæ—¶å‘æ¨¡å‹æä¾›ç¤ºä¾‹è¾“å…¥å’Œè¾“å‡ºã€‚å‘LLMæä¾›å°‘é‡è¿™æ ·çš„ç¤ºä¾‹è¢«ç§°ä¸ºå°‘é‡ç¤ºä¾‹ï¼Œè¿™æ˜¯ä¸€ç§ç®€å•ä½†å¼ºå¤§çš„æŒ‡å¯¼ç”Ÿæˆçš„æ–¹å¼ï¼Œåœ¨æŸäº›æƒ…å†µä¸‹å¯ä»¥æ˜¾è‘—æé«˜æ¨¡å‹æ€§èƒ½ã€‚</font>

<font style="color:rgb(28, 30, 33);">å°‘é‡ç¤ºä¾‹æç¤ºæ¨¡æ¿å¯ä»¥ç”±ä¸€ç»„ç¤ºä¾‹æˆ–ä¸€ä¸ªè´Ÿè´£ä»å®šä¹‰çš„é›†åˆä¸­é€‰æ‹©ä¸€éƒ¨åˆ†ç¤ºä¾‹çš„</font>[<font style="color:rgb(28, 30, 33);">ç¤ºä¾‹é€‰æ‹©å™¨</font>](https://api.python.langchain.com/en/latest/example_selectors/langchain_core.example_selectors.base.BaseExampleSelector.html)<font style="color:rgb(28, 30, 33);">ç±»æ„å»ºã€‚</font>

<font style="color:rgb(28, 30, 33);">é…ç½®ä¸€ä¸ªæ ¼å¼åŒ–ç¨‹åºï¼Œå°†å°‘é‡ç¤ºä¾‹æ ¼å¼åŒ–ä¸ºå­—ç¬¦ä¸²ã€‚è¿™ä¸ªæ ¼å¼åŒ–ç¨‹åºåº”è¯¥æ˜¯ä¸€ä¸ª</font>`<font style="color:rgb(28, 30, 33);">PromptTemplate</font>`<font style="color:rgb(28, 30, 33);">å¯¹è±¡ã€‚</font>

```python
from langchain_core.prompts import PromptTemplate
example_prompt = PromptTemplate.from_template("é—®é¢˜ï¼š{question}\n{answer}")
```

### <font style="color:rgb(28, 30, 33);">åˆ›å»ºç¤ºä¾‹é›†åˆ</font>
<font style="color:rgb(28, 30, 33);">æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å°†åˆ›å»ºä¸€ä¸ªå°‘é‡ç¤ºä¾‹çš„åˆ—è¡¨ã€‚æ¯ä¸ªç¤ºä¾‹åº”è¯¥æ˜¯ä¸€ä¸ªå­—å…¸ï¼Œè¡¨ç¤ºæˆ‘ä»¬ä¸Šé¢å®šä¹‰çš„æ ¼å¼åŒ–æç¤ºçš„ç¤ºä¾‹è¾“å…¥ã€‚</font>

```python
examples = [
    {
        "question": "è°æ´»å¾—æ›´é•¿ï¼Œç©†ç½•é»˜å¾·Â·é˜¿é‡Œè¿˜æ˜¯è‰¾ä¼¦Â·å›¾çµï¼Ÿ",
        "answer": """
æ˜¯å¦éœ€è¦åç»­é—®é¢˜ï¼šæ˜¯çš„ã€‚
åç»­é—®é¢˜ï¼šç©†ç½•é»˜å¾·Â·é˜¿é‡Œå»ä¸–æ—¶å¤šå¤§å¹´çºªï¼Ÿ
ä¸­é—´ç­”æ¡ˆï¼šç©†ç½•é»˜å¾·Â·é˜¿é‡Œå»ä¸–æ—¶74å²ã€‚
åç»­é—®é¢˜ï¼šè‰¾ä¼¦Â·å›¾çµå»ä¸–æ—¶å¤šå¤§å¹´çºªï¼Ÿ
ä¸­é—´ç­”æ¡ˆï¼šè‰¾ä¼¦Â·å›¾çµå»ä¸–æ—¶41å²ã€‚
æ‰€ä»¥æœ€ç»ˆç­”æ¡ˆæ˜¯ï¼šç©†ç½•é»˜å¾·Â·é˜¿é‡Œ
""",
    },
    {
        "question": "å…‹é›·æ ¼æ–¯åˆ—è¡¨çš„åˆ›å§‹äººæ˜¯ä»€ä¹ˆæ—¶å€™å‡ºç”Ÿçš„ï¼Ÿ",
        "answer": """
æ˜¯å¦éœ€è¦åç»­é—®é¢˜ï¼šæ˜¯çš„ã€‚
åç»­é—®é¢˜ï¼šå…‹é›·æ ¼æ–¯åˆ—è¡¨çš„åˆ›å§‹äººæ˜¯è°ï¼Ÿ
ä¸­é—´ç­”æ¡ˆï¼šå…‹é›·æ ¼æ–¯åˆ—è¡¨çš„åˆ›å§‹äººæ˜¯å…‹é›·æ ¼Â·çº½é©¬å…‹ã€‚
åç»­é—®é¢˜ï¼šå…‹é›·æ ¼Â·çº½é©¬å…‹æ˜¯ä»€ä¹ˆæ—¶å€™å‡ºç”Ÿçš„ï¼Ÿ
ä¸­é—´ç­”æ¡ˆï¼šå…‹é›·æ ¼Â·çº½é©¬å…‹äº1952å¹´12æœˆ6æ—¥å‡ºç”Ÿã€‚
æ‰€ä»¥æœ€ç»ˆç­”æ¡ˆæ˜¯ï¼š1952å¹´12æœˆ6æ—¥
""",
    },
    {
        "question": "ä¹”æ²»Â·åç››é¡¿çš„å¤–ç¥–çˆ¶æ˜¯è°ï¼Ÿ",
        "answer": """
æ˜¯å¦éœ€è¦åç»­é—®é¢˜ï¼šæ˜¯çš„ã€‚
åç»­é—®é¢˜ï¼šä¹”æ²»Â·åç››é¡¿çš„æ¯äº²æ˜¯è°ï¼Ÿ
ä¸­é—´ç­”æ¡ˆï¼šä¹”æ²»Â·åç››é¡¿çš„æ¯äº²æ˜¯ç›ä¸½Â·æ³¢å°”Â·åç››é¡¿ã€‚
åç»­é—®é¢˜ï¼šç›ä¸½Â·æ³¢å°”Â·åç››é¡¿çš„çˆ¶äº²æ˜¯è°ï¼Ÿ
ä¸­é—´ç­”æ¡ˆï¼šç›ä¸½Â·æ³¢å°”Â·åç››é¡¿çš„çˆ¶äº²æ˜¯çº¦ç‘Ÿå¤«Â·æ³¢å°”ã€‚
æ‰€ä»¥æœ€ç»ˆç­”æ¡ˆæ˜¯ï¼šçº¦ç‘Ÿå¤«Â·æ³¢å°”
""",
    },
    {
        "question": "ã€Šå¤§ç™½é²¨ã€‹å’Œã€Šçš‡å®¶èµŒåœºã€‹çš„å¯¼æ¼”éƒ½æ¥è‡ªåŒä¸€ä¸ªå›½å®¶å—ï¼Ÿ",
        "answer": """
æ˜¯å¦éœ€è¦åç»­é—®é¢˜ï¼šæ˜¯çš„ã€‚
åç»­é—®é¢˜ï¼šã€Šå¤§ç™½é²¨ã€‹çš„å¯¼æ¼”æ˜¯è°ï¼Ÿ
ä¸­é—´ç­”æ¡ˆï¼šã€Šå¤§ç™½é²¨ã€‹çš„å¯¼æ¼”æ˜¯å²è’‚æ–‡Â·æ–¯çš®å°”ä¼¯æ ¼ã€‚
åç»­é—®é¢˜ï¼šå²è’‚æ–‡Â·æ–¯çš®å°”ä¼¯æ ¼æ¥è‡ªå“ªä¸ªå›½å®¶ï¼Ÿ
ä¸­é—´ç­”æ¡ˆï¼šç¾å›½ã€‚
åç»­é—®é¢˜ï¼šã€Šçš‡å®¶èµŒåœºã€‹çš„å¯¼æ¼”æ˜¯è°ï¼Ÿ
ä¸­é—´ç­”æ¡ˆï¼šã€Šçš‡å®¶èµŒåœºã€‹çš„å¯¼æ¼”æ˜¯é©¬ä¸Â·åè´å°”ã€‚
åç»­é—®é¢˜ï¼šé©¬ä¸Â·åè´å°”æ¥è‡ªå“ªä¸ªå›½å®¶ï¼Ÿ
ä¸­é—´ç­”æ¡ˆï¼šæ–°è¥¿å…°ã€‚
æ‰€ä»¥æœ€ç»ˆç­”æ¡ˆæ˜¯ï¼šä¸æ˜¯
""",
    },
]
```

<font style="color:rgb(28, 30, 33);">è®©æˆ‘ä»¬ä½¿ç”¨å…¶ä¸­ä¸€ä¸ªç¤ºä¾‹æµ‹è¯•æ ¼å¼åŒ–æç¤ºï¼š</font>

```python
print(example_prompt.invoke(examples[0]).to_string())
```

```plain
é—®é¢˜ï¼šè°æ´»å¾—æ›´é•¿ï¼Œç©†ç½•é»˜å¾·Â·é˜¿é‡Œè¿˜æ˜¯è‰¾ä¼¦Â·å›¾çµï¼Ÿ

æ˜¯å¦éœ€è¦åç»­é—®é¢˜ï¼šæ˜¯çš„ã€‚
åç»­é—®é¢˜ï¼šç©†ç½•é»˜å¾·Â·é˜¿é‡Œå»ä¸–æ—¶å¤šå¤§å¹´çºªï¼Ÿ
ä¸­é—´ç­”æ¡ˆï¼šç©†ç½•é»˜å¾·Â·é˜¿é‡Œå»ä¸–æ—¶74å²ã€‚
åç»­é—®é¢˜ï¼šè‰¾ä¼¦Â·å›¾çµå»ä¸–æ—¶å¤šå¤§å¹´çºªï¼Ÿ
ä¸­é—´ç­”æ¡ˆï¼šè‰¾ä¼¦Â·å›¾çµå»ä¸–æ—¶41å²ã€‚
æ‰€ä»¥æœ€ç»ˆç­”æ¡ˆæ˜¯ï¼šç©†ç½•é»˜å¾·Â·é˜¿é‡Œ
```

### <font style="color:rgb(28, 30, 33);">å°†ç¤ºä¾‹å’Œæ ¼å¼åŒ–ç¨‹åºä¼ é€’ç»™</font>`<font style="color:rgb(28, 30, 33);">FewShotPromptTemplate</font>`
<font style="color:rgb(28, 30, 33);">æœ€åï¼Œåˆ›å»ºä¸€ä¸ª</font>[<font style="color:rgb(28, 30, 33);">FewShotPromptTemplate</font>](https://api.python.langchain.com/en/latest/prompts/langchain_core.prompts.few_shot.FewShotPromptTemplate.html)<font style="color:rgb(28, 30, 33);">å¯¹è±¡ã€‚è¯¥å¯¹è±¡æ¥å—å°‘é‡ç¤ºä¾‹å’Œå°‘é‡ç¤ºä¾‹çš„æ ¼å¼åŒ–ç¨‹åºã€‚å½“æ ¼å¼åŒ–æ­¤</font>`<font style="color:rgb(28, 30, 33);">FewShotPromptTemplate</font>`<font style="color:rgb(28, 30, 33);">æ—¶ï¼Œå®ƒä½¿ç”¨</font>`<font style="color:rgb(28, 30, 33);">example_prompt</font>`<font style="color:rgb(28, 30, 33);">æ ¼å¼åŒ–ä¼ é€’çš„ç¤ºä¾‹ï¼Œç„¶åå°†å®ƒä»¬æ·»åŠ åˆ°</font>`<font style="color:rgb(28, 30, 33);">suffix</font>`<font style="color:rgb(28, 30, 33);">ä¹‹å‰çš„æœ€ç»ˆæç¤ºä¸­ï¼š</font>

```python
from langchain_core.prompts import FewShotPromptTemplate
prompt = FewShotPromptTemplate(
    examples=examples,
    example_prompt=example_prompt,
    suffix="é—®é¢˜ï¼š{input}",
    input_variables=["input"],
)
print(
    prompt.invoke({"input": "ä¹”æ²»Â·åç››é¡¿çš„çˆ¶äº²æ˜¯è°ï¼Ÿ"}).to_string()
)
```

```plain
é—®é¢˜ï¼šè°æ´»å¾—æ›´é•¿ï¼Œç©†ç½•é»˜å¾·Â·é˜¿é‡Œè¿˜æ˜¯è‰¾ä¼¦Â·å›¾çµï¼Ÿ

æ˜¯å¦éœ€è¦åç»­é—®é¢˜ï¼šæ˜¯çš„ã€‚
åç»­é—®é¢˜ï¼šç©†ç½•é»˜å¾·Â·é˜¿é‡Œå»ä¸–æ—¶å¤šå¤§å¹´çºªï¼Ÿ
ä¸­é—´ç­”æ¡ˆï¼šç©†ç½•é»˜å¾·Â·é˜¿é‡Œå»ä¸–æ—¶74å²ã€‚
åç»­é—®é¢˜ï¼šè‰¾ä¼¦Â·å›¾çµå»ä¸–æ—¶å¤šå¤§å¹´çºªï¼Ÿ
ä¸­é—´ç­”æ¡ˆï¼šè‰¾ä¼¦Â·å›¾çµå»ä¸–æ—¶41å²ã€‚
æ‰€ä»¥æœ€ç»ˆç­”æ¡ˆæ˜¯ï¼šç©†ç½•é»˜å¾·Â·é˜¿é‡Œ


é—®é¢˜ï¼šå…‹é›·æ ¼æ–¯åˆ—è¡¨çš„åˆ›å§‹äººæ˜¯ä»€ä¹ˆæ—¶å€™å‡ºç”Ÿçš„ï¼Ÿ

æ˜¯å¦éœ€è¦åç»­é—®é¢˜ï¼šæ˜¯çš„ã€‚
åç»­é—®é¢˜ï¼šå…‹é›·æ ¼æ–¯åˆ—è¡¨çš„åˆ›å§‹äººæ˜¯è°ï¼Ÿ
ä¸­é—´ç­”æ¡ˆï¼šå…‹é›·æ ¼æ–¯åˆ—è¡¨çš„åˆ›å§‹äººæ˜¯å…‹é›·æ ¼Â·çº½é©¬å…‹ã€‚
åç»­é—®é¢˜ï¼šå…‹é›·æ ¼Â·çº½é©¬å…‹æ˜¯ä»€ä¹ˆæ—¶å€™å‡ºç”Ÿçš„ï¼Ÿ
ä¸­é—´ç­”æ¡ˆï¼šå…‹é›·æ ¼Â·çº½é©¬å…‹äº1952å¹´12æœˆ6æ—¥å‡ºç”Ÿã€‚
æ‰€ä»¥æœ€ç»ˆç­”æ¡ˆæ˜¯ï¼š1952å¹´12æœˆ6æ—¥


é—®é¢˜ï¼šä¹”æ²»Â·åç››é¡¿çš„å¤–ç¥–çˆ¶æ˜¯è°ï¼Ÿ

æ˜¯å¦éœ€è¦åç»­é—®é¢˜ï¼šæ˜¯çš„ã€‚
åç»­é—®é¢˜ï¼šä¹”æ²»Â·åç››é¡¿çš„æ¯äº²æ˜¯è°ï¼Ÿ
ä¸­é—´ç­”æ¡ˆï¼šä¹”æ²»Â·åç››é¡¿çš„æ¯äº²æ˜¯ç›ä¸½Â·æ³¢å°”Â·åç››é¡¿ã€‚
åç»­é—®é¢˜ï¼šç›ä¸½Â·æ³¢å°”Â·åç››é¡¿çš„çˆ¶äº²æ˜¯è°ï¼Ÿ
ä¸­é—´ç­”æ¡ˆï¼šç›ä¸½Â·æ³¢å°”Â·åç››é¡¿çš„çˆ¶äº²æ˜¯çº¦ç‘Ÿå¤«Â·æ³¢å°”ã€‚
æ‰€ä»¥æœ€ç»ˆç­”æ¡ˆæ˜¯ï¼šçº¦ç‘Ÿå¤«Â·æ³¢å°”


é—®é¢˜ï¼šã€Šå¤§ç™½é²¨ã€‹å’Œã€Šçš‡å®¶èµŒåœºã€‹çš„å¯¼æ¼”éƒ½æ¥è‡ªåŒä¸€ä¸ªå›½å®¶å—ï¼Ÿ

æ˜¯å¦éœ€è¦åç»­é—®é¢˜ï¼šæ˜¯çš„ã€‚
åç»­é—®é¢˜ï¼šã€Šå¤§ç™½é²¨ã€‹çš„å¯¼æ¼”æ˜¯è°ï¼Ÿ
ä¸­é—´ç­”æ¡ˆï¼šã€Šå¤§ç™½é²¨ã€‹çš„å¯¼æ¼”æ˜¯å²è’‚æ–‡Â·æ–¯çš®å°”ä¼¯æ ¼ã€‚
åç»­é—®é¢˜ï¼šå²è’‚æ–‡Â·æ–¯çš®å°”ä¼¯æ ¼æ¥è‡ªå“ªä¸ªå›½å®¶ï¼Ÿ
ä¸­é—´ç­”æ¡ˆï¼šç¾å›½ã€‚
åç»­é—®é¢˜ï¼šã€Šçš‡å®¶èµŒåœºã€‹çš„å¯¼æ¼”æ˜¯è°ï¼Ÿ
ä¸­é—´ç­”æ¡ˆï¼šã€Šçš‡å®¶èµŒåœºã€‹çš„å¯¼æ¼”æ˜¯é©¬ä¸Â·åè´å°”ã€‚
åç»­é—®é¢˜ï¼šé©¬ä¸Â·åè´å°”æ¥è‡ªå“ªä¸ªå›½å®¶ï¼Ÿ
ä¸­é—´ç­”æ¡ˆï¼šæ–°è¥¿å…°ã€‚
æ‰€ä»¥æœ€ç»ˆç­”æ¡ˆæ˜¯ï¼šä¸æ˜¯


é—®é¢˜ï¼šä¹”æ²»Â·åç››é¡¿çš„çˆ¶äº²æ˜¯è°ï¼Ÿ
```

<font style="color:rgb(28, 30, 33);">é€šè¿‡å‘æ¨¡å‹æä¾›è¿™æ ·çš„ç¤ºä¾‹ï¼Œæˆ‘ä»¬å¯ä»¥å¼•å¯¼æ¨¡å‹åšå‡ºæ›´å¥½çš„å›åº”ã€‚</font>

## <font style="color:#080808;background-color:#ffffff;">Example selectors(</font><font style="color:rgb(28, 30, 33);">ç¤ºä¾‹é€‰æ‹©å™¨)</font>
<font style="color:rgb(28, 30, 33);">æˆ‘ä»¬å°†é‡ç”¨ä¸Šä¸€èŠ‚ä¸­çš„ç¤ºä¾‹é›†å’Œæ ¼å¼åŒ–ç¨‹åºã€‚ä½†æ˜¯ï¼Œæˆ‘ä»¬ä¸ä¼šç›´æ¥å°†ç¤ºä¾‹é¦ˆé€åˆ°</font><font style="color:rgb(28, 30, 33);"> </font>`<font style="color:rgb(28, 30, 33);">FewShotPromptTemplate</font>`<font style="color:rgb(28, 30, 33);"> </font><font style="color:rgb(28, 30, 33);">å¯¹è±¡ä¸­ï¼Œè€Œæ˜¯å°†å®ƒä»¬é¦ˆé€åˆ°åä¸º</font><font style="color:rgb(28, 30, 33);"> </font>[<font style="color:rgb(28, 30, 33);">SemanticSimilarityExampleSelector</font>](https://api.python.langchain.com/en/latest/example_selectors/langchain_core.example_selectors.semantic_similarity.SemanticSimilarityExampleSelector.html)<font style="color:rgb(28, 30, 33);"> </font><font style="color:rgb(28, 30, 33);">çš„</font><font style="color:rgb(28, 30, 33);"> </font>`<font style="color:rgb(28, 30, 33);">ExampleSelector</font>`<font style="color:rgb(28, 30, 33);"> </font><font style="color:rgb(28, 30, 33);">å®ç°å®ä¾‹ä¸­ã€‚è¯¥ç±»æ ¹æ®è¾“å…¥ä¸å°‘æ ·æœ¬ç¤ºä¾‹çš„ç›¸ä¼¼æ€§é€‰æ‹©åˆå§‹é›†åˆä¸­çš„å°‘æ ·æœ¬ç¤ºä¾‹ã€‚å®ƒä½¿ç”¨åµŒå…¥æ¨¡å‹è®¡ç®—è¾“å…¥ä¸å°‘æ ·æœ¬ç¤ºä¾‹ä¹‹é—´çš„ç›¸ä¼¼æ€§ï¼Œä»¥åŠå‘é‡å­˜å‚¨åº“æ‰§è¡Œæœ€è¿‘é‚»æœç´¢ã€‚</font>

<font style="color:rgb(28, 30, 33);">ä¸ºäº†å±•ç¤ºå®ƒçš„æ ·å­ï¼Œè®©æˆ‘ä»¬åˆå§‹åŒ–ä¸€ä¸ªå®ä¾‹å¹¶åœ¨éš”ç¦»ç¯å¢ƒä¸­è°ƒç”¨å®ƒï¼š</font>

```python
from langchain_chroma import Chroma
from langchain_core.example_selectors import SemanticSimilarityExampleSelector
from langchain_openai import OpenAIEmbeddings
example_selector = SemanticSimilarityExampleSelector.from_examples(
    # è¿™æ˜¯å¯ä¾›é€‰æ‹©çš„ç¤ºä¾‹åˆ—è¡¨ã€‚
    examples,
    # è¿™æ˜¯ç”¨äºç”ŸæˆåµŒå…¥çš„åµŒå…¥ç±»ï¼Œç”¨äºè¡¡é‡è¯­ä¹‰ç›¸ä¼¼æ€§ã€‚
    OpenAIEmbeddings(),
    # è¿™æ˜¯ç”¨äºå­˜å‚¨åµŒå…¥å¹¶è¿›è¡Œç›¸ä¼¼æ€§æœç´¢çš„ VectorStore ç±»ã€‚
    Chroma,
    # è¿™æ˜¯è¦ç”Ÿæˆçš„ç¤ºä¾‹æ•°é‡ã€‚
    k=1,
)
# é€‰æ‹©ä¸è¾“å…¥æœ€ç›¸ä¼¼çš„ç¤ºä¾‹ã€‚
question = "ç›ä¸½Â·æ³¢å°”Â·åç››é¡¿çš„çˆ¶äº²æ˜¯è°ï¼Ÿ"
selected_examples = example_selector.select_examples({"question": question})
print(f"ä¸è¾“å…¥æœ€ç›¸ä¼¼çš„ç¤ºä¾‹: {question}")
for example in selected_examples:
    print("\n")
    for k, v in example.items():
        print(f"{k}: {v}")
```

```python
ä¸è¾“å…¥æœ€ç›¸ä¼¼çš„ç¤ºä¾‹: ç›ä¸½Â·æ³¢å°”Â·åç››é¡¿çš„çˆ¶äº²æ˜¯è°ï¼Ÿ
answer: 
æ˜¯å¦éœ€è¦åç»­é—®é¢˜ï¼šæ˜¯çš„ã€‚
åç»­é—®é¢˜ï¼šä¹”æ²»Â·åç››é¡¿çš„æ¯äº²æ˜¯è°ï¼Ÿ
ä¸­é—´ç­”æ¡ˆï¼šä¹”æ²»Â·åç››é¡¿çš„æ¯äº²æ˜¯ç›ä¸½Â·æ³¢å°”Â·åç››é¡¿ã€‚
åç»­é—®é¢˜ï¼šç›ä¸½Â·æ³¢å°”Â·åç››é¡¿çš„çˆ¶äº²æ˜¯è°ï¼Ÿ
ä¸­é—´ç­”æ¡ˆï¼šç›ä¸½Â·æ³¢å°”Â·åç››é¡¿çš„çˆ¶äº²æ˜¯çº¦ç‘Ÿå¤«Â·æ³¢å°”ã€‚
æ‰€ä»¥æœ€ç»ˆç­”æ¡ˆæ˜¯ï¼šçº¦ç‘Ÿå¤«Â·æ³¢å°”
question: ä¹”æ²»Â·åç››é¡¿çš„å¤–ç¥–çˆ¶æ˜¯è°ï¼Ÿ
```

Chroma å®‰è£…æŠ¥é”™

```powershell
pip install langchain-chroma
error: Microsoft Visual C++ 14.0 or greater is required. Get it with "Microsoft C++ Build Tools": https://visualstudio.microsoft.com/visual-cpp-build-tools/
[end of output]
```

è§£å†³æ–¹æ¡ˆï¼šéœ€è¦å…ˆä¸‹è½½visual-cpp-build-toolsï¼Œå†æ‰§è¡Œpip install langchain-chroma

ä¸‹è½½åœ°å€ï¼š[https://visualstudio.microsoft.com/zh-hans/visual-cpp-build-tools/](https://visualstudio.microsoft.com/zh-hans/visual-cpp-build-tools/)

![](https://cdn.nlark.com/yuque/0/2024/png/2424104/1722411859844-7a02ba32-0a30-45ee-808c-b20cfd00d1a9.png)

<font style="color:rgb(28, 30, 33);">ç°åœ¨ï¼Œè®©æˆ‘ä»¬åˆ›å»ºä¸€ä¸ª </font>`<font style="color:rgb(28, 30, 33);">FewShotPromptTemplate</font>`<font style="color:rgb(28, 30, 33);"> å¯¹è±¡ã€‚è¯¥å¯¹è±¡æ¥å—ç¤ºä¾‹é€‰æ‹©å™¨å’Œç”¨äºå°‘æ ·æœ¬ç¤ºä¾‹çš„æ ¼å¼åŒ–ç¨‹åºæç¤ºã€‚</font>

```python
prompt = FewShotPromptTemplate(
    example_selector=example_selector,
    example_prompt=example_prompt,
    suffix="Question: {input}",
    input_variables=["input"],
)
print(
    prompt.invoke({"input": "ç›ä¸½Â·æ³¢å°”Â·åç››é¡¿çš„çˆ¶äº²æ˜¯è°ï¼Ÿ"}).to_string()
)
```

```plain
é—®é¢˜ï¼šä¹”æ²»Â·åç››é¡¿çš„å¤–ç¥–çˆ¶æ˜¯è°ï¼Ÿ
æ˜¯å¦éœ€è¦åç»­é—®é¢˜ï¼šæ˜¯çš„ã€‚
åç»­é—®é¢˜ï¼šä¹”æ²»Â·åç››é¡¿çš„æ¯äº²æ˜¯è°ï¼Ÿ
ä¸­é—´ç­”æ¡ˆï¼šä¹”æ²»Â·åç››é¡¿çš„æ¯äº²æ˜¯ç›ä¸½Â·æ³¢å°”Â·åç››é¡¿ã€‚
åç»­é—®é¢˜ï¼šç›ä¸½Â·æ³¢å°”Â·åç››é¡¿çš„çˆ¶äº²æ˜¯è°ï¼Ÿ
ä¸­é—´ç­”æ¡ˆï¼šç›ä¸½Â·æ³¢å°”Â·åç››é¡¿çš„çˆ¶äº²æ˜¯çº¦ç‘Ÿå¤«Â·æ³¢å°”ã€‚
æ‰€ä»¥æœ€ç»ˆç­”æ¡ˆæ˜¯ï¼šçº¦ç‘Ÿå¤«Â·æ³¢å°”
Question: ç›ä¸½Â·æ³¢å°”Â·åç››é¡¿çš„çˆ¶äº²æ˜¯è°ï¼Ÿ
```



# LangServe
## <font style="color:rgb(28, 30, 33);">æ¦‚è¿°</font>
[<font style="color:rgb(28, 30, 33);">LangServe</font>](https://github.com/langchain-ai/langserve)<font style="color:rgb(28, 30, 33);"> </font><font style="color:rgb(28, 30, 33);">ğŸ¦œ</font><font style="color:rgb(28, 30, 33);">ï¸</font><font style="color:rgb(28, 30, 33);">ğŸ“</font><font style="color:rgb(28, 30, 33);"> </font><font style="color:rgb(28, 30, 33);">å¸®åŠ©å¼€å‘è€…å°† </font>`<font style="color:rgb(28, 30, 33);">LangChain</font>`<font style="color:rgb(28, 30, 33);"> </font>[<font style="color:rgb(28, 30, 33);">å¯è¿è¡Œå’Œé“¾</font>](https://python.langchain.com/docs/expression_language/)<font style="color:rgb(28, 30, 33);">éƒ¨ç½²ä¸º REST APIã€‚</font>

<font style="color:rgb(28, 30, 33);">è¯¥åº“é›†æˆäº†</font><font style="color:rgb(28, 30, 33);"> </font>[<font style="color:rgb(28, 30, 33);">FastAPI</font>](https://fastapi.tiangolo.com/)<font style="color:rgb(28, 30, 33);"> </font><font style="color:rgb(28, 30, 33);">å¹¶ä½¿ç”¨</font><font style="color:rgb(28, 30, 33);"> </font>[<font style="color:rgb(28, 30, 33);">pydantic</font>](https://docs.pydantic.dev/latest/)<font style="color:rgb(28, 30, 33);"> </font><font style="color:rgb(28, 30, 33);">è¿›è¡Œæ•°æ®éªŒè¯ã€‚</font>

**<font style="color:rgb(28, 30, 33);">Pydantic</font>**<font style="color:rgb(28, 30, 33);"> æ˜¯ä¸€ä¸ªåœ¨ Pythonä¸­ç”¨äºæ•°æ®éªŒè¯å’Œè§£æçš„ç¬¬ä¸‰æ–¹åº“ï¼Œç°åœ¨æ˜¯Pythonä¸­ä½¿ç”¨å¹¿æ³›çš„æ•°æ®éªŒè¯åº“ã€‚</font>

+ <font style="color:rgb(28, 30, 33);">å®ƒåˆ©ç”¨å£°æ˜å¼çš„æ–¹å¼å®šä¹‰æ•°æ®æ¨¡å‹å’ŒPython ç±»å‹æç¤ºçš„å¼ºå¤§åŠŸèƒ½æ¥æ‰§è¡Œæ•°æ®éªŒè¯å’Œåºåˆ—åŒ–ï¼Œä½¿æ‚¨çš„ä»£ç æ›´å¯é ã€æ›´å¯è¯»ã€æ›´ç®€æ´ä¸”æ›´æ˜“äºè°ƒè¯•ã€‚ã€‚</font>
+ <font style="color:rgb(28, 30, 33);">å®ƒè¿˜å¯ä»¥ä»æ¨¡å‹ç”Ÿæˆ JSON æ¶æ„ï¼Œæä¾›äº†è‡ªåŠ¨ç”Ÿæˆæ–‡æ¡£ç­‰åŠŸèƒ½ï¼Œä»è€Œè½»æ¾ä¸å…¶ä»–å·¥å…·é›†æˆ</font>

<font style="color:rgb(28, 30, 33);">æ­¤å¤–ï¼Œå®ƒæä¾›äº†ä¸€ä¸ªå®¢æˆ·ç«¯ï¼Œå¯ç”¨äºè°ƒç”¨éƒ¨ç½²åœ¨æœåŠ¡å™¨ä¸Šçš„å¯è¿è¡Œå¯¹è±¡ã€‚JavaScript å®¢æˆ·ç«¯å¯åœ¨</font><font style="color:rgb(28, 30, 33);"> </font>[<font style="color:rgb(28, 30, 33);">LangChain.js</font>](https://js.langchain.com/docs/ecosystem/langserve)<font style="color:rgb(28, 30, 33);"> </font><font style="color:rgb(28, 30, 33);">ä¸­æ‰¾åˆ°ã€‚</font>

## <font style="color:rgb(28, 30, 33);">ç‰¹æ€§</font>
+ <font style="color:rgb(28, 30, 33);">ä» LangChain å¯¹è±¡è‡ªåŠ¨æ¨æ–­è¾“å…¥å’Œè¾“å‡ºæ¨¡å¼ï¼Œå¹¶åœ¨æ¯æ¬¡ API è°ƒç”¨ä¸­æ‰§è¡Œï¼Œæä¾›ä¸°å¯Œçš„é”™è¯¯ä¿¡æ¯</font>
+ <font style="color:rgb(28, 30, 33);">å¸¦æœ‰ JSONSchema å’Œ Swagger çš„ API æ–‡æ¡£é¡µé¢ï¼ˆæ’å…¥ç¤ºä¾‹é“¾æ¥ï¼‰</font>
+ <font style="color:rgb(28, 30, 33);">é«˜æ•ˆçš„</font><font style="color:rgb(28, 30, 33);"> </font>`<font style="color:rgb(28, 30, 33);">/invoke</font>`<font style="color:rgb(28, 30, 33);">ã€</font>`<font style="color:rgb(28, 30, 33);">/batch</font>`<font style="color:rgb(28, 30, 33);"> </font><font style="color:rgb(28, 30, 33);">å’Œ</font><font style="color:rgb(28, 30, 33);"> </font>`<font style="color:rgb(28, 30, 33);">/stream</font>`<font style="color:rgb(28, 30, 33);"> </font><font style="color:rgb(28, 30, 33);">ç«¯ç‚¹ï¼Œæ”¯æŒå•ä¸ªæœåŠ¡å™¨ä¸Šçš„å¤šä¸ªå¹¶å‘è¯·æ±‚</font>
+ `<font style="color:rgb(28, 30, 33);">/stream_log</font>`<font style="color:rgb(28, 30, 33);"> </font><font style="color:rgb(28, 30, 33);">ç«¯ç‚¹ï¼Œç”¨äºæµå¼ä¼ è¾“é“¾/ä»£ç†çš„æ‰€æœ‰ï¼ˆæˆ–éƒ¨åˆ†ï¼‰ä¸­é—´æ­¥éª¤</font>
+ **<font style="color:rgb(28, 30, 33);">æ–°åŠŸèƒ½</font>**<font style="color:rgb(28, 30, 33);"> è‡ª 0.0.40 ç‰ˆæœ¬èµ·ï¼Œæ”¯æŒ </font>`<font style="color:rgb(28, 30, 33);">/stream_events</font>`<font style="color:rgb(28, 30, 33);">ï¼Œä½¿æµå¼ä¼ è¾“æ›´åŠ ç®€ä¾¿ï¼Œæ— éœ€è§£æ </font>`<font style="color:rgb(28, 30, 33);">/stream_log</font>`<font style="color:rgb(28, 30, 33);"> çš„è¾“å‡ºã€‚</font>
+ <font style="color:rgb(28, 30, 33);">ä½¿ç”¨ç»è¿‡ä¸¥æ ¼æµ‹è¯•çš„å¼€æº Python åº“æ„å»ºï¼Œå¦‚ FastAPIã€Pydanticã€uvloop å’Œ asyncioã€‚</font>
+ <font style="color:rgb(28, 30, 33);">ä½¿ç”¨å®¢æˆ·ç«¯ SDK è°ƒç”¨ LangServe æœåŠ¡å™¨ï¼Œå°±åƒæœ¬åœ°è¿è¡Œå¯è¿è¡Œå¯¹è±¡ä¸€æ ·ï¼ˆæˆ–ç›´æ¥è°ƒç”¨ HTTP APIï¼‰</font>

## <font style="color:rgb(28, 30, 33);">é™åˆ¶</font>
+ <font style="color:rgb(28, 30, 33);">ç›®å‰ä¸æ”¯æŒæœåŠ¡å™¨å‘èµ·çš„äº‹ä»¶çš„å®¢æˆ·ç«¯å›è°ƒ</font>
+ <font style="color:rgb(28, 30, 33);">å½“ä½¿ç”¨ Pydantic V2 æ—¶ï¼Œå°†ä¸ä¼šç”Ÿæˆ OpenAPI æ–‡æ¡£ã€‚FastAPI ä¸æ”¯æŒ</font>[<font style="color:rgb(28, 30, 33);">æ··åˆä½¿ç”¨ pydantic v1 å’Œ v2 å‘½åç©ºé—´</font>](https://github.com/tiangolo/fastapi/issues/10360)<font style="color:rgb(28, 30, 33);">ã€‚æ›´å¤šç»†èŠ‚è¯·å‚è§ä¸‹é¢çš„ç« èŠ‚ã€‚</font>

## <font style="color:rgb(28, 30, 33);">å®‰è£…</font>
<font style="color:rgb(28, 30, 33);">å¯¹äºå®¢æˆ·ç«¯å’ŒæœåŠ¡å™¨ï¼š</font>

```bash
pip install --upgrade "langserve[all]" 
```

<font style="color:rgb(28, 30, 33);">æˆ–è€…å¯¹äºå®¢æˆ·ç«¯ä»£ç ï¼Œ</font>`<font style="color:rgb(28, 30, 33);">pip install "langserve[client]"</font>`<font style="color:rgb(28, 30, 33);">ï¼Œå¯¹äºæœåŠ¡å™¨ä»£ç ï¼Œ</font>`<font style="color:rgb(28, 30, 33);">pip install "langserve[server]"</font>`<font style="color:rgb(28, 30, 33);">ã€‚</font>

## <font style="color:rgb(28, 30, 33);">LangChain CLI </font><font style="color:rgb(28, 30, 33);">ğŸ› ï¸</font>
<font style="color:rgb(28, 30, 33);">ä½¿ç”¨</font><font style="color:rgb(28, 30, 33);"> </font>`<font style="color:rgb(28, 30, 33);">LangChain</font>`<font style="color:rgb(28, 30, 33);"> </font><font style="color:rgb(28, 30, 33);">CLI å¿«é€Ÿå¯åŠ¨</font><font style="color:rgb(28, 30, 33);"> </font>`<font style="color:rgb(28, 30, 33);">LangServe</font>`<font style="color:rgb(28, 30, 33);"> </font><font style="color:rgb(28, 30, 33);">é¡¹ç›®ã€‚</font>

<font style="color:rgb(28, 30, 33);">è¦ä½¿ç”¨ langchain CLIï¼Œè¯·ç¡®ä¿å·²å®‰è£…æœ€æ–°ç‰ˆæœ¬çš„ </font>`<font style="color:rgb(28, 30, 33);">langchain-cli</font>`<font style="color:rgb(28, 30, 33);">ã€‚æ‚¨å¯ä»¥ä½¿ç”¨ </font>`<font style="color:rgb(28, 30, 33);">pip install -U langchain-cli</font>`<font style="color:rgb(28, 30, 33);"> è¿›è¡Œå®‰è£…ã€‚</font>

## <font style="color:rgb(28, 30, 33);">è®¾ç½®</font>
**<font style="color:rgb(28, 30, 33);">æ³¨æ„</font>**<font style="color:rgb(28, 30, 33);">ï¼šæˆ‘ä»¬ä½¿ç”¨</font><font style="color:rgb(28, 30, 33);"> </font>`<font style="color:rgb(28, 30, 33);">poetry</font>`<font style="color:rgb(28, 30, 33);"> </font><font style="color:rgb(28, 30, 33);">è¿›è¡Œä¾èµ–ç®¡ç†ã€‚è¯·å‚é˜… poetry</font><font style="color:rgb(28, 30, 33);"> </font>[<font style="color:rgb(28, 30, 33);">æ–‡æ¡£</font>](https://python-poetry.org/docs/)<font style="color:rgb(28, 30, 33);"> </font><font style="color:rgb(28, 30, 33);">äº†è§£æ›´å¤šä¿¡æ¯ã€‚</font>

### <font style="color:rgb(28, 30, 33);">1. ä½¿ç”¨ langchain cli å‘½ä»¤åˆ›å»ºæ–°åº”ç”¨</font>
```plain
langchain app new my-app
```

### <font style="color:rgb(28, 30, 33);">2. åœ¨ add_routes ä¸­å®šä¹‰å¯è¿è¡Œå¯¹è±¡ã€‚è½¬åˆ° server.py å¹¶ç¼–è¾‘</font>
```plain
add_routes(app. NotImplemented)
```

### <font style="color:rgb(28, 30, 33);">3. ä½¿ç”¨ </font>`<font style="color:rgb(28, 30, 33);">poetry</font>`<font style="color:rgb(28, 30, 33);"> æ·»åŠ ç¬¬ä¸‰æ–¹åŒ…ï¼ˆä¾‹å¦‚ langchain-openaiã€langchain-anthropicã€langchain-mistral ç­‰ï¼‰</font>
```powershell
#å®‰è£…pipxï¼Œå‚è€ƒï¼šhttps://pipx.pypa.io/stable/installation/
pip install pipx 
#åŠ å…¥åˆ°ç¯å¢ƒå˜é‡ï¼Œéœ€è¦é‡å¯PyCharm 
pipx ensurepath

# å®‰è£…poetryï¼Œå‚è€ƒï¼šhttps://python-poetry.org/docs/
pipx install poetry


#å®‰è£… langchain-openai åº“ï¼Œä¾‹å¦‚ï¼špoetry add [package-name]
poetry add langchain
poetry add langchain-openai 
```

### <font style="color:rgb(28, 30, 33);">4. è®¾ç½®ç›¸å…³ç¯å¢ƒå˜é‡ã€‚ä¾‹å¦‚ï¼Œ</font>
```plain
export OPENAI_API_KEY="sk-..."
```

### <font style="color:rgb(28, 30, 33);">5. å¯åŠ¨æ‚¨çš„åº”ç”¨</font>
```plain
poetry run langchain serve --port=8000
```

## <font style="color:rgb(28, 30, 33);">ç¤ºä¾‹åº”ç”¨</font>
## <font style="color:rgb(28, 30, 33);">æœåŠ¡å™¨</font>
<font style="color:rgb(28, 30, 33);">ä»¥ä¸‹æ˜¯ä¸€ä¸ªéƒ¨ç½² OpenAI èŠå¤©æ¨¡å‹ï¼Œè®²è¿°æœ‰å…³ç‰¹å®šä¸»é¢˜ç¬‘è¯çš„é“¾çš„æœåŠ¡å™¨ã€‚</font>

```python
#!/usr/bin/env python
from fastapi import FastAPI
from langchain_openai import ChatOpenAI
from langserve import add_routes
app = FastAPI(
    title="LangChain æœåŠ¡å™¨",
    version="1.0",
    description="ä½¿ç”¨ Langchain çš„ Runnable æ¥å£çš„ç®€å• API æœåŠ¡å™¨",
)
add_routes(
    app,
    ChatOpenAI(model="gpt-4"),
    path="/openai",
)
if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="localhost", port=8000)
```

<font style="color:rgb(28, 30, 33);">å¦‚æœæ‚¨æ‰“ç®—ä»æµè§ˆå™¨è°ƒç”¨æ‚¨çš„ç«¯ç‚¹ï¼Œæ‚¨è¿˜éœ€è¦è®¾ç½® CORS å¤´ã€‚</font>

<font style="color:rgb(28, 30, 33);">æ‚¨å¯ä»¥ä½¿ç”¨ FastAPI çš„å†…ç½®ä¸­é—´ä»¶æ¥å®ç°ï¼š</font>

```python
from fastapi.middleware.cors import CORSMiddleware
# è®¾ç½®æ‰€æœ‰å¯ç”¨ CORS çš„æ¥æº
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
    expose_headers=["*"],
)
```

## <font style="color:rgb(28, 30, 33);">æ–‡æ¡£</font>
<font style="color:rgb(28, 30, 33);">å¦‚æœæ‚¨å·²éƒ¨ç½²ä¸Šè¿°æœåŠ¡å™¨ï¼Œå¯ä»¥ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤æŸ¥çœ‹ç”Ÿæˆçš„ OpenAPI æ–‡æ¡£ï¼š</font>

æ–‡æ¡£åœ°å€ï¼š[http://localhost:8000/docs](http://localhost:8000/docs)

```plain
curl localhost:8000/docs
```

<font style="color:rgb(28, 30, 33);">è¯·ç¡®ä¿</font>**<font style="color:rgb(28, 30, 33);">æ·»åŠ </font>**<font style="color:rgb(28, 30, 33);"> </font>`<font style="color:rgb(28, 30, 33);">/docs</font>`<font style="color:rgb(28, 30, 33);"> </font><font style="color:rgb(28, 30, 33);">åç¼€ã€‚</font>

âš ï¸ é¦–é¡µ `/` æ²¡æœ‰è¢«**è®¾è®¡**å®šä¹‰ï¼Œå› æ­¤ `curl localhost:8000` æˆ–è®¿é—®è¯¥ URL

å°†è¿”å› 404ã€‚å¦‚æœæ‚¨æƒ³åœ¨ `/` ä¸Šæœ‰å†…å®¹ï¼Œè¯·å®šä¹‰ä¸€ä¸ªç«¯ç‚¹ `@app.get("/")`ã€‚

## <font style="color:rgb(28, 30, 33);">å®¢æˆ·ç«¯</font>
<font style="color:rgb(28, 30, 33);">Python SDK</font>

```python
from langchain.schema.runnable import RunnableMap
from langchain_core.prompts import ChatPromptTemplate
from langserve import RemoteRunnable

openai = RemoteRunnable("http://localhost:8000/openai/")
prompt = ChatPromptTemplate.from_messages(
    [("system", "ä½ æ˜¯ä¸€ä¸ªå–œæ¬¢å†™æ•…äº‹çš„åŠ©æ‰‹"), ("system", "å†™ä¸€ä¸ªæ•…äº‹ï¼Œä¸»é¢˜æ˜¯ï¼š {topic}")]
)
# å¯ä»¥å®šä¹‰è‡ªå®šä¹‰é“¾
chain = prompt | RunnableMap({
    "openai": openai
})
response = chain.batch([{"topic": "çŒ«"}])
print(response)
#[{'openai': AIMessage(content='ä»å‰ï¼Œæœ‰ä¸€ä¸ªå«åšè‚–æ©çš„ç”·å­©ï¼Œä»–åœ¨ä¸€ä¸ªå®é™çš„ä¹¡æ‘é‡Œç”Ÿæ´»ã€‚ä¸€å¤©ï¼Œä»–åœ¨å®¶çš„åé™¢å‘ç°äº†ä¸€ä¸ªå°å°çš„ï¼ŒèŒèŒçš„çŒ«å’ªã€‚è¿™åªçŒ«å’ªæœ‰ä¸€åŒå¤§å¤§çš„è“è‰²çœ¼ç›ï¼Œæ¯›è‰²å¦‚åŒæœéœèˆ¬çš„ç²‰è‰²ï¼Œçœ‹èµ·æ¥éå¸¸å¯çˆ±ã€‚\n\nè‚–æ©æŠŠè¿™åªçŒ«å’ªå¸¦å›äº†å®¶ï¼Œä»–ç»™å¥¹å–åä¸ºâ€œæ¨±èŠ±â€ï¼Œå› ä¸ºå¥¹çš„æ¯›è‰²è®©ä»–è”æƒ³åˆ°æ˜¥å¤©ç››å¼€çš„æ¨±èŠ±ã€‚è‚–æ©éå¸¸å–œæ¬¢æ¨±èŠ±ï¼Œä»–ç”¨å¿ƒç…§é¡¾å¥¹ï¼Œæ¯å¤©éƒ½ä¼šä¸ºå¥¹å‡†å¤‡æ–°é²œçš„é£Ÿç‰©å’Œæ¸…æ°´ï¼Œè¿˜ä¼šé™ªå¥¹ç©è€ï¼Œå¸¦å¥¹å»æ•£æ­¥ã€‚\n\næ¨±èŠ±ä¹Ÿéå¸¸å–œæ¬¢è‚–æ©ï¼Œå¥¹ä¼šåœ¨è‚–æ©è¯»ä¹¦çš„æ—¶å€™èººåœ¨ä»–çš„è„šè¾¹ï¼Œä¼šåœ¨ä»–ä¼¤å¿ƒçš„æ—¶å€™å®‰æ…°ä»–ï¼Œæ¯å½“è‚–æ©å›å®¶çš„æ—¶å€™ï¼Œå¥¹æ€»æ˜¯ç¬¬ä¸€ä¸ªè·‘å‡ºæ¥è¿æ¥ä»–ã€‚å¯æ˜¯ï¼Œæ¨±èŠ±æœ‰ä¸€ä¸ªç§˜å¯†ï¼Œå¥¹å…¶å®æ˜¯ä¸€åªä¼šè¯´äººè¯çš„çŒ«ã€‚\n\nè¿™ä¸ªç§˜å¯†æ˜¯åœ¨ä¸€ä¸ªæœˆåœ†çš„å¤œæ™šè¢«è‚–æ©å‘ç°çš„ã€‚é‚£å¤©æ™šä¸Šï¼Œè‚–æ©åšäº†ä¸€ä¸ªå™©æ¢¦ï¼Œä»–ä»æ¢¦ä¸­æƒŠé†’ï¼Œå‘ç°æ¨±èŠ±æ­£ååœ¨ä»–çš„åºŠè¾¹ï¼Œç”¨äººçš„è¯­è¨€å®‰æ…°ä»–ã€‚è‚–æ©ä¸€å¼€å§‹ä»¥ä¸ºè‡ªå·±åœ¨åšæ¢¦ï¼Œä½†æ˜¯å½“ä»–æ¸…é†’è¿‡æ¥ï¼Œæ¨±èŠ±è¿˜åœ¨ç»§ç»­è®²è¯ï¼Œä»–æ‰çŸ¥é“è¿™æ˜¯çœŸçš„ã€‚\n\næ¨±èŠ±å‘è‚–æ©è§£é‡Šï¼Œå¥¹æ˜¯ä¸€åªæ¥è‡ªç¥ç§˜çš„çŒ«å’ªå›½åº¦çš„ä½¿è€…ï¼Œå¥¹çš„ä»»åŠ¡æ˜¯ä¿æŠ¤å’Œå¸®åŠ©é‚£äº›å–„è‰¯å’Œçˆ±æŠ¤åŠ¨ç‰©çš„äººã€‚è‚–æ©å› ä¸ºå¯¹å¥¹çš„å–„è‰¯å’Œç…§é¡¾ï¼Œä½¿å¥¹å†³å®šå‘ä»–å±•ç°çœŸå®çš„è‡ªæˆ‘ã€‚\n\nè‚–æ©è™½ç„¶æ„Ÿåˆ°æƒŠè®¶ï¼Œä½†ä»–å¹¶æ²¡æœ‰å› æ­¤è€Œå®³æ€•æˆ–è€…æ’æ–¥æ¨±èŠ±ã€‚ä»–è§‰å¾—è¿™åªä½¿å¾—ä»–æ›´åŠ å–œæ¬¢æ¨±èŠ±ï¼Œè§‰å¾—è¿™æ˜¯ä»–ä»¬ä¹‹é—´çš„ç‰¹æ®Šçº½å¸¦ã€‚\n\nä»é‚£å¤©å¼€å§‹ï¼Œè‚–æ©å’Œæ¨±èŠ±çš„å…³ç³»å˜å¾—æ›´åŠ äº²å¯†ï¼Œä»–ä»¬åƒæœ€å¥½çš„æœ‹å‹ä¸€æ ·ï¼Œåˆ†äº«å½¼æ­¤çš„ç§˜å¯†ï¼Œä¸€èµ·åº¦è¿‡å¿«ä¹çš„æ—¶å…‰ã€‚æ¨±èŠ±ä¹Ÿç”¨å¥¹çš„æ™ºæ…§å’ŒåŠ›é‡ï¼Œå¸®åŠ©è‚–æ©è§£å†³äº†è®¸å¤šå›°æ‰°ä»–çš„é—®é¢˜ã€‚\n\nè®¸å¤šå¹´è¿‡å»äº†ï¼Œè‚–æ©é•¿å¤§äº†ï¼Œä»–ç¦»å¼€äº†ä¹¡æ‘ï¼Œå»äº†åŸå¸‚ä¸Šå¤§å­¦ã€‚ä½†æ˜¯ï¼Œæ— è®ºä»–èµ°åˆ°å“ªé‡Œï¼Œéƒ½ä¼šå¸¦ç€æ¨±èŠ±ã€‚ä»–ä»¬çš„å‹æƒ…å’Œäº’ç›¸çš„é™ªä¼´ï¼Œè®©ä»–ä»¬æ— è®ºåœ¨å“ªé‡Œï¼Œéƒ½èƒ½æ„Ÿåˆ°å®¶çš„æ¸©æš–ã€‚\n\næœ€åï¼Œè‚–æ©æˆä¸ºäº†ä¸€åä½œå®¶ï¼Œä»–å†™ä¸‹äº†è‡ªå·±å’Œæ¨±èŠ±çš„æ•…äº‹ï¼Œè¿™ä¸ªæ•…äº‹è¢«äººä»¬å¹¿ä¸ºä¼ æ’­ï¼Œè®©æ›´å¤šçš„äººçŸ¥é“äº†è¿™ä¸ªå…³äºå–„è‰¯ã€å‹æƒ…å’Œå‹‡æ°”çš„æ•…äº‹ã€‚è€Œæ¨±èŠ±ï¼Œä¹Ÿæ°¸è¿œé™ªä¼´åœ¨è‚–æ©çš„èº«è¾¹ï¼Œæˆä¸ºä»–ç”Ÿæ´»ä¸­ä¸å¯æˆ–ç¼ºçš„ä¸€éƒ¨åˆ†ã€‚\n\nè¿™å°±æ˜¯è‚–æ©å’Œæ¨±èŠ±çš„æ•…äº‹ï¼Œä¸€ä¸ªå…³äºç”·å­©å’Œä»–çš„çŒ«çš„æ•…äº‹ï¼Œå……æ»¡äº†å¥‡è¿¹ã€æ¸©æš–å’Œçˆ±ã€‚', response_metadata={'token_usage': {'completion_tokens': 1050, 'prompt_tokens': 33, 'total_tokens': 1083}, 'model_name': 'gpt-4-0613', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-c44f1624-ea75-424b-ba3d-e741baf44bda-0', usage_metadata={'input_tokens': 33, 'output_tokens': 1050, 'total_tokens': 1083})}]

```

<font style="color:rgb(28, 30, 33);">åœ¨ TypeScript ä¸­ï¼ˆéœ€è¦ LangChain.js ç‰ˆæœ¬ 0.0.166 æˆ–æ›´é«˜ï¼‰ï¼š</font>

```typescript
import { RemoteRunnable } from "@langchain/core/runnables/remote";
const chain = new RemoteRunnable({
  url: `http://localhost:8000/openai/`,
});
const result = await chain.invoke({
  topic: "cats",
});
```

<font style="color:rgb(28, 30, 33);">ä½¿ç”¨</font><font style="color:rgb(28, 30, 33);"> </font>`<font style="color:rgb(28, 30, 33);">requests</font>`<font style="color:rgb(28, 30, 33);"> </font><font style="color:rgb(28, 30, 33);">çš„ Python ä»£ç ï¼š</font>

```python
import requests
response = requests.post(
    "http://localhost:8000/openai",
    json={'input': {'topic': 'cats'}}
)
response.json()
```

<font style="color:rgb(28, 30, 33);">æ‚¨ä¹Ÿå¯ä»¥ä½¿ç”¨</font><font style="color:rgb(28, 30, 33);"> </font>`<font style="color:rgb(28, 30, 33);">curl</font>`<font style="color:rgb(28, 30, 33);">ï¼š</font>

```powershell
curl --location --request POST 'http://localhost:8000/openai/stream' \
    --header 'Content-Type: application/json' \
    --data-raw '{
        "input": {
            "topic": "ç‹—"
        }
    }'
```

## <font style="color:rgb(28, 30, 33);">ç«¯ç‚¹</font>
<font style="color:rgb(28, 30, 33);">ä»¥ä¸‹ä»£ç ï¼š</font>

```python
...
add_routes(
    app,
    runnable,
    path="/my_runnable",
)
```

<font style="color:rgb(28, 30, 33);">å°†ä»¥ä¸‹ç«¯ç‚¹æ·»åŠ åˆ°æœåŠ¡å™¨ï¼š</font>

+ `<font style="color:rgb(28, 30, 33);">POST /my_runnable/invoke</font>`<font style="color:rgb(28, 30, 33);"> </font><font style="color:rgb(28, 30, 33);">- å¯¹å•ä¸ªè¾“å…¥è°ƒç”¨å¯è¿è¡Œé¡¹</font>
+ `<font style="color:rgb(28, 30, 33);">POST /my_runnable/batch</font>`<font style="color:rgb(28, 30, 33);"> </font><font style="color:rgb(28, 30, 33);">- å¯¹ä¸€æ‰¹è¾“å…¥è°ƒç”¨å¯è¿è¡Œé¡¹</font>
+ `<font style="color:rgb(28, 30, 33);">POST /my_runnable/stream</font>`<font style="color:rgb(28, 30, 33);"> </font><font style="color:rgb(28, 30, 33);">- å¯¹å•ä¸ªè¾“å…¥è°ƒç”¨å¹¶æµå¼ä¼ è¾“è¾“å‡º</font>
+ `<font style="color:rgb(28, 30, 33);">POST /my_runnable/stream_log</font>`<font style="color:rgb(28, 30, 33);"> </font><font style="color:rgb(28, 30, 33);">- å¯¹å•ä¸ªè¾“å…¥è°ƒç”¨å¹¶æµå¼ä¼ è¾“è¾“å‡ºï¼Œ</font>

<font style="color:rgb(28, 30, 33);">åŒ…æ‹¬ç”Ÿæˆçš„ä¸­é—´æ­¥éª¤çš„è¾“å‡º</font>

+ `<font style="color:rgb(28, 30, 33);">POST /my_runnable/astream_events</font>`<font style="color:rgb(28, 30, 33);"> </font><font style="color:rgb(28, 30, 33);">- å¯¹å•ä¸ªè¾“å…¥è°ƒç”¨å¹¶åœ¨ç”Ÿæˆæ—¶æµå¼ä¼ è¾“äº‹ä»¶ï¼Œ</font>

<font style="color:rgb(28, 30, 33);">åŒ…æ‹¬æ¥è‡ªä¸­é—´æ­¥éª¤çš„äº‹ä»¶ã€‚</font>

+ `<font style="color:rgb(28, 30, 33);">GET /my_runnable/input_schema</font>`<font style="color:rgb(28, 30, 33);"> </font><font style="color:rgb(28, 30, 33);">- å¯è¿è¡Œé¡¹çš„è¾“å…¥çš„ JSON æ¨¡å¼</font>
+ `<font style="color:rgb(28, 30, 33);">GET /my_runnable/output_schema</font>`<font style="color:rgb(28, 30, 33);"> </font><font style="color:rgb(28, 30, 33);">- å¯è¿è¡Œé¡¹çš„è¾“å‡ºçš„ JSON æ¨¡å¼</font>
+ `<font style="color:rgb(28, 30, 33);">GET /my_runnable/config_schema</font>`<font style="color:rgb(28, 30, 33);"> </font><font style="color:rgb(28, 30, 33);">- å¯è¿è¡Œé¡¹çš„é…ç½®çš„ JSON æ¨¡å¼</font>

<font style="color:rgb(28, 30, 33);">è¿™äº›ç«¯ç‚¹ä¸</font>[<font style="color:rgb(28, 30, 33);">LangChain è¡¨è¾¾å¼è¯­è¨€æ¥å£</font>](https://python.langchain.com/docs/expression_language/interface)<font style="color:rgb(28, 30, 33);">ç›¸åŒ¹é… --</font>



# ä¸º Chain æ·»åŠ  Message history (Memory)å•è¡Œåˆå§‹åŒ– chat model
## <font style="color:rgb(28, 30, 33);">å¯¹è¯çŠ¶æ€Chainä¼ é€’</font>
<font style="color:rgb(28, 30, 33);">åœ¨æ„å»ºèŠå¤©æœºå™¨äººæ—¶ï¼Œå°†å¯¹è¯çŠ¶æ€ä¼ é€’åˆ°é“¾ä¸­ä»¥åŠä»é“¾ä¸­ä¼ å‡ºå¯¹è¯çŠ¶æ€è‡³å…³é‡è¦ã€‚</font>[<font style="color:rgb(28, 30, 33);">RunnableWithMessageHistory</font>](https://api.python.langchain.com/en/latest/runnables/langchain_core.runnables.history.RunnableWithMessageHistory.html#langchain_core.runnables.history.RunnableWithMessageHistory)<font style="color:rgb(28, 30, 33);"> ç±»è®©æˆ‘ä»¬èƒ½å¤Ÿå‘æŸäº›ç±»å‹çš„é“¾ä¸­æ·»åŠ æ¶ˆæ¯å†å²ã€‚å®ƒåŒ…è£…å¦ä¸€ä¸ª Runnable å¹¶ç®¡ç†å…¶èŠå¤©æ¶ˆæ¯å†å²ã€‚</font>

<font style="color:rgb(28, 30, 33);">å…·ä½“æ¥è¯´ï¼Œå®ƒå¯ç”¨äºä»»ä½•æ¥å—ä»¥ä¸‹ä¹‹ä¸€ä½œä¸ºè¾“å…¥çš„ Runnableï¼š</font>

+ <font style="color:rgb(28, 30, 33);">ä¸€ç³»åˆ—</font><font style="color:rgb(28, 30, 33);"> </font>[<font style="color:rgb(28, 30, 33);">BaseMessages</font>](http://www.aidoczh.com/langchain/v0.2/docs/concepts/#message-types)
+ <font style="color:rgb(28, 30, 33);">å…·æœ‰ä»¥åºåˆ—</font><font style="color:rgb(28, 30, 33);"> </font>`<font style="color:rgb(28, 30, 33);">BaseMessages</font>`<font style="color:rgb(28, 30, 33);"> </font><font style="color:rgb(28, 30, 33);">ä½œä¸ºå€¼çš„é”®çš„å­—å…¸</font>
+ <font style="color:rgb(28, 30, 33);">å…·æœ‰ä»¥å­—ç¬¦ä¸²æˆ–åºåˆ—</font><font style="color:rgb(28, 30, 33);"> </font>`<font style="color:rgb(28, 30, 33);">BaseMessages</font>`<font style="color:rgb(28, 30, 33);"> </font><font style="color:rgb(28, 30, 33);">ä½œä¸ºæœ€æ–°æ¶ˆæ¯çš„å€¼çš„é”®å’Œä¸€ä¸ªæ¥å—å†å²æ¶ˆæ¯çš„å•ç‹¬é”®çš„å­—å…¸</font>

<font style="color:rgb(28, 30, 33);">å¹¶å°†ä»¥ä¸‹ä¹‹ä¸€ä½œä¸ºè¾“å‡ºè¿”å›ï¼š</font>

+ <font style="color:rgb(28, 30, 33);">å¯è§†ä¸º</font><font style="color:rgb(28, 30, 33);"> </font>`<font style="color:rgb(28, 30, 33);">AIMessage</font>`<font style="color:rgb(28, 30, 33);"> </font><font style="color:rgb(28, 30, 33);">å†…å®¹çš„å­—ç¬¦ä¸²</font>
+ <font style="color:rgb(28, 30, 33);">ä¸€ç³»åˆ—</font><font style="color:rgb(28, 30, 33);"> </font>`<font style="color:rgb(28, 30, 33);">BaseMessage</font>`
+ <font style="color:rgb(28, 30, 33);">å…·æœ‰åŒ…å«ä¸€ç³»åˆ—</font><font style="color:rgb(28, 30, 33);"> </font>`<font style="color:rgb(28, 30, 33);">BaseMessage</font>`<font style="color:rgb(28, 30, 33);"> </font><font style="color:rgb(28, 30, 33);">çš„é”®çš„å­—å…¸</font>

<font style="color:rgb(28, 30, 33);">è®©æˆ‘ä»¬çœ‹ä¸€äº›ç¤ºä¾‹ä»¥äº†è§£å…¶å·¥ä½œåŸç†ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬æ„å»ºä¸€ä¸ª Runnableï¼ˆæ­¤å¤„æ¥å—å­—å…¸ä½œä¸ºè¾“å…¥å¹¶è¿”å›æ¶ˆæ¯ä½œä¸ºè¾“å‡ºï¼‰ï¼š</font>

```python
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_openai.chat_models import ChatOpenAI
prompt = ChatPromptTemplate.from_messages(
    [
        (
            "system",
            "You're an assistant who's good at {ability}. Respond in 20 words or fewer",
        ),
        MessagesPlaceholder(variable_name="history"),
        ("human", "{input}"),
    ]
)
runnable = prompt | model
```

```python
first=ChatPromptTemplate(input_variables=['ability', 'history', 'input'], input_types={'history': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]]}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['ability'], template="You're an assistant who's good at {ability}. Respond in 20 words or fewer")), MessagesPlaceholder(variable_name='history'), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}'))]) last=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x0000026A478DB440>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x0000026A478FCD10>, model_name='gpt-4', openai_api_key=SecretStr('**********'), openai_proxy='')

```

<font style="color:rgb(28, 30, 33);">è¦ç®¡ç†æ¶ˆæ¯å†å²ï¼Œæˆ‘ä»¬éœ€è¦ï¼š</font>

1. <font style="color:rgb(28, 30, 33);">æ­¤ Runnableï¼›</font>
2. <font style="color:rgb(28, 30, 33);">ä¸€ä¸ªè¿”å›</font><font style="color:rgb(28, 30, 33);"> </font>`<font style="color:rgb(28, 30, 33);">BaseChatMessageHistory</font>`<font style="color:rgb(28, 30, 33);"> </font><font style="color:rgb(28, 30, 33);">å®ä¾‹çš„å¯è°ƒç”¨å¯¹è±¡ã€‚</font>



## <font style="color:rgb(28, 30, 33);">èŠå¤©å†å²å­˜å‚¨åœ¨å†…å­˜</font>
<font style="color:rgb(28, 30, 33);">ä¸‹é¢æˆ‘ä»¬å±•ç¤ºä¸€ä¸ªç®€å•çš„ç¤ºä¾‹ï¼Œå…¶ä¸­èŠå¤©å†å²ä¿å­˜åœ¨å†…å­˜ä¸­ï¼Œæ­¤å¤„é€šè¿‡å…¨å±€ Python å­—å…¸å®ç°ã€‚</font>

<font style="color:rgb(28, 30, 33);">æˆ‘ä»¬æ„å»ºä¸€ä¸ªåä¸º</font><font style="color:rgb(28, 30, 33);"> </font>`<font style="color:rgb(28, 30, 33);">get_session_history</font>`<font style="color:rgb(28, 30, 33);"> </font><font style="color:rgb(28, 30, 33);">çš„å¯è°ƒç”¨å¯¹è±¡ï¼Œå¼•ç”¨æ­¤å­—å…¸ä»¥è¿”å›</font><font style="color:rgb(28, 30, 33);"> </font>`<font style="color:rgb(28, 30, 33);">ChatMessageHistory</font>`<font style="color:rgb(28, 30, 33);"> </font><font style="color:rgb(28, 30, 33);">å®ä¾‹ã€‚é€šè¿‡åœ¨è¿è¡Œæ—¶å‘</font><font style="color:rgb(28, 30, 33);"> </font>`<font style="color:rgb(28, 30, 33);">RunnableWithMessageHistory</font>`<font style="color:rgb(28, 30, 33);"> </font><font style="color:rgb(28, 30, 33);">ä¼ é€’é…ç½®ï¼Œå¯ä»¥æŒ‡å®šå¯è°ƒç”¨å¯¹è±¡çš„å‚æ•°ã€‚é»˜è®¤æƒ…å†µä¸‹ï¼ŒæœŸæœ›é…ç½®å‚æ•°æ˜¯ä¸€ä¸ªå­—ç¬¦ä¸²</font><font style="color:rgb(28, 30, 33);"> </font>`<font style="color:rgb(28, 30, 33);">session_id</font>`<font style="color:rgb(28, 30, 33);">ã€‚å¯ä»¥é€šè¿‡</font><font style="color:rgb(28, 30, 33);"> </font>`<font style="color:rgb(28, 30, 33);">history_factory_config</font>`<font style="color:rgb(28, 30, 33);"> </font><font style="color:rgb(28, 30, 33);">å…³é”®å­—å‚æ•°è¿›è¡Œè°ƒæ•´ã€‚</font>

<font style="color:rgb(28, 30, 33);">ä½¿ç”¨å•å‚æ•°é»˜è®¤å€¼ï¼š</font>

```python
from langchain_community.chat_message_histories import ChatMessageHistory
from langchain_core.chat_history import BaseChatMessageHistory
from langchain_core.runnables.history import RunnableWithMessageHistory
store = {}
def get_session_history(session_id: str) -> BaseChatMessageHistory:
    if session_id not in store:
        store[session_id] = ChatMessageHistory()
    return store[session_id]
with_message_history = RunnableWithMessageHistory(
    runnable,
    get_session_history,
    input_messages_key="input",
    history_messages_key="history",
)
```

<font style="color:rgb(28, 30, 33);">è¯·æ³¨æ„ï¼Œæˆ‘ä»¬å·²æŒ‡å®šäº†</font><font style="color:rgb(28, 30, 33);"> </font>`<font style="color:rgb(28, 30, 33);">input_messages_key</font>`<font style="color:rgb(28, 30, 33);">ï¼ˆè¦è§†ä¸ºæœ€æ–°è¾“å…¥æ¶ˆæ¯çš„é”®ï¼‰å’Œ</font><font style="color:rgb(28, 30, 33);"> </font>`<font style="color:rgb(28, 30, 33);">history_messages_key</font>`<font style="color:rgb(28, 30, 33);">ï¼ˆè¦æ·»åŠ å†å²æ¶ˆæ¯çš„é”®ï¼‰ã€‚</font>

<font style="color:rgb(28, 30, 33);">åœ¨è°ƒç”¨æ­¤æ–° Runnable æ—¶ï¼Œæˆ‘ä»¬é€šè¿‡é…ç½®å‚æ•°æŒ‡å®šç›¸åº”çš„èŠå¤©å†å²ï¼š</font>

```python
with_message_history.invoke(
    {"ability": "math", "input": "ä½™å¼¦æ˜¯ä»€ä¹ˆæ„æ€ï¼Ÿ"},
    config={"configurable": {"session_id": "abc123"}},
)
```

```plain
content='ä½™å¼¦æ˜¯ä¸€ä¸ªæ•°å­¦å‡½æ•°ï¼Œé€šå¸¸åœ¨ä¸‰è§’å­¦ä¸­ä½¿ç”¨ï¼Œè¡¨ç¤ºç›´è§’ä¸‰è§’å½¢çš„é‚»è¾¹å’Œæ–œè¾¹çš„æ¯”ä¾‹ã€‚' response_metadata={'token_usage': {'completion_tokens': 38, 'prompt_tokens': 38, 'total_tokens': 76}, 'model_name': 'gpt-4-0613', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-9aa23716-3959-476d-9386-6d433266e060-0' usage_metadata={'input_tokens': 38, 'output_tokens': 38, 'total_tokens': 76}
```

```python
# è®°ä½
with_message_history.invoke(
    {"ability": "math", "input": "ä»€ä¹ˆ?"},
    config={"configurable": {"session_id": "abc123"}},
)
```

```python
content='ä½™å¼¦æ˜¯ä¸€ä¸ªæ•°å­¦æœ¯è¯­ï¼Œç”¨äºæè¿°ç›´è§’ä¸‰è§’å½¢ä¸­çš„è§’åº¦å…³ç³»ã€‚' response_metadata={'token_usage': {'completion_tokens': 26, 'prompt_tokens': 88, 'total_tokens': 114}, 'model_name': 'gpt-4-0613', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-f77baf90-6a13-4f48-991a-28e60ece84e8-0' usage_metadata={'input_tokens': 88, 'output_tokens': 26, 'total_tokens': 114}
```

```python
# æ–°çš„ session_id --> ä¸è®°å¾—äº†ã€‚
with_message_history.invoke(
    {"ability": "math", "input": "ä»€ä¹ˆ?"},
    config={"configurable": {"session_id": "def234"}},
)
```

```python
content='å¯¹ä¸èµ·ï¼Œæˆ‘æ²¡æ˜ç™½ä½ çš„é—®é¢˜ã€‚ä½ èƒ½å†è¯¦ç»†ä¸€ç‚¹å—ï¼Ÿæˆ‘å¾ˆæ“…é•¿æ•°å­¦ã€‚' response_metadata={'token_usage': {'completion_tokens': 34, 'prompt_tokens': 32, 'total_tokens': 66}, 'model_name': 'gpt-4-0613', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-3f69d281-a850-452f-8055-df70d4936630-0' usage_metadata={'input_tokens': 32, 'output_tokens': 34, 'total_tokens': 66}
```

## 
# åŸºäº LangChain çš„ Chatbot: Chat History
## <font style="color:rgb(28, 30, 33);">é…ç½®ä¼šè¯å”¯ä¸€é”®</font>
<font style="color:rgb(28, 30, 33);">æˆ‘ä»¬å¯ä»¥é€šè¿‡å‘ </font>`<font style="color:rgb(28, 30, 33);">history_factory_config</font>`<font style="color:rgb(28, 30, 33);"> å‚æ•°ä¼ é€’ä¸€ä¸ª </font>`<font style="color:rgb(28, 30, 33);">ConfigurableFieldSpec</font>`<font style="color:rgb(28, 30, 33);"> å¯¹è±¡åˆ—è¡¨æ¥è‡ªå®šä¹‰è·Ÿè¸ªæ¶ˆæ¯å†å²çš„é…ç½®å‚æ•°ã€‚ä¸‹é¢æˆ‘ä»¬ä½¿ç”¨äº†ä¸¤ä¸ªå‚æ•°ï¼š</font>`<font style="color:rgb(28, 30, 33);">user_id</font>`<font style="color:rgb(28, 30, 33);"> å’Œ </font>`<font style="color:rgb(28, 30, 33);">conversation_id</font>`<font style="color:rgb(28, 30, 33);">ã€‚</font>

<font style="color:rgb(28, 30, 33);">é…ç½®user_idå’Œconversation_idä½œä¸ºä¼šè¯å”¯ä¸€é”®</font>

```python
from langchain_core.runnables import ConfigurableFieldSpec
store = {}
def get_session_history(user_id: str, conversation_id: str) -> BaseChatMessageHistory:
    if (user_id, conversation_id) not in store:
        store[(user_id, conversation_id)] = ChatMessageHistory()
    return store[(user_id, conversation_id)]
with_message_history = RunnableWithMessageHistory(
    runnable,
    get_session_history,
    input_messages_key="input",
    history_messages_key="history",
    history_factory_config=[
        ConfigurableFieldSpec(
            id="user_id",
            annotation=str,
            name="User ID",
            description="ç”¨æˆ·çš„å”¯ä¸€æ ‡è¯†ç¬¦ã€‚",
            default="",
            is_shared=True,
        ),
        ConfigurableFieldSpec(
            id="conversation_id",
            annotation=str,
            name="Conversation ID",
            description="å¯¹è¯çš„å”¯ä¸€æ ‡è¯†ç¬¦ã€‚",
            default="",
            is_shared=True,
        ),
    ],
)
with_message_history.invoke(
    {"ability": "math", "input": "ä½™å¼¦æ˜¯ä»€ä¹ˆæ„æ€ï¼Ÿ"},
    config={"configurable": {"user_id": "123", "conversation_id": "1"}},
)
```

```plain
content='å¯¹ä¸èµ·ï¼Œä½ èƒ½æä¾›ä¸€äº›æ›´è¯¦ç»†çš„ä¿¡æ¯å—ï¼Ÿæˆ‘ä¼šå¾ˆé«˜å…´å¸®åŠ©ä½ è§£å†³æ•°å­¦é—®é¢˜ã€‚' response_metadata={'token_usage': {'completion_tokens': 38, 'prompt_tokens': 32, 'total_tokens': 70}, 'model_name': 'gpt-4-0613', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-02030348-7bbb-4f76-8c68-61785d012c26-0' usage_metadata={'input_tokens': 32, 'output_tokens': 38, 'total_tokens': 70}
```



<font style="color:rgb(28, 30, 33);">åœ¨è®¸å¤šæƒ…å†µä¸‹ï¼ŒæŒä¹…åŒ–å¯¹è¯å†å²æ˜¯å¯å–çš„ã€‚</font>`<font style="color:rgb(28, 30, 33);">RunnableWithMessageHistory</font>`<font style="color:rgb(28, 30, 33);"> å¯¹äº </font>`<font style="color:rgb(28, 30, 33);">get_session_history</font>`<font style="color:rgb(28, 30, 33);"> å¯è°ƒç”¨å¦‚ä½•æ£€ç´¢å…¶èŠå¤©æ¶ˆæ¯å†å²æ˜¯ä¸­ç«‹çš„ã€‚è¯·å‚è§è¿™é‡Œ ï¼Œè¿™æ˜¯ä¸€ä¸ªä½¿ç”¨æœ¬åœ°æ–‡ä»¶ç³»ç»Ÿçš„ç¤ºä¾‹ã€‚ä¸‹é¢æˆ‘ä»¬æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨ Redisã€‚è¯·æŸ¥çœ‹å†…å­˜é›†æˆ é¡µé¢ï¼Œä»¥è·å–ä½¿ç”¨å…¶ä»–æä¾›ç¨‹åºçš„èŠå¤©æ¶ˆæ¯å†å²çš„å®ç°ã€‚</font>

## <font style="color:rgb(28, 30, 33);">æ¶ˆæ¯æŒä¹…åŒ–</font>
<font style="color:rgb(28, 30, 33);">è¯·æŸ¥çœ‹ </font>[<font style="color:rgb(28, 30, 33);">memory integrations</font>](https://integrations.langchain.com/memory)<font style="color:rgb(28, 30, 33);"> é¡µé¢ï¼Œäº†è§£ä½¿ç”¨ Redis å’Œå…¶ä»–æä¾›ç¨‹åºå®ç°èŠå¤©æ¶ˆæ¯å†å²çš„æ–¹æ³•ã€‚è¿™é‡Œæˆ‘ä»¬æ¼”ç¤ºä½¿ç”¨å†…å­˜ä¸­çš„ </font>`<font style="color:rgb(28, 30, 33);">ChatMessageHistory</font>`<font style="color:rgb(28, 30, 33);"> ä»¥åŠä½¿ç”¨ </font>`<font style="color:rgb(28, 30, 33);">RedisChatMessageHistory</font>`<font style="color:rgb(28, 30, 33);"> è¿›è¡Œæ›´æŒä¹…å­˜å‚¨ã€‚</font>

### <font style="color:rgb(28, 30, 33);">é…ç½®redisç¯å¢ƒ</font>
<font style="color:rgb(28, 30, 33);">å¦‚æœå°šæœªå®‰è£… Redisï¼Œæˆ‘ä»¬éœ€è¦å®‰è£…å®ƒï¼š</font>

```python
%pip install --upgrade --quiet redis
```

<font style="color:rgb(28, 30, 33);">å¦‚æœæˆ‘ä»¬æ²¡æœ‰ç°æœ‰çš„ Redis éƒ¨ç½²å¯ä»¥è¿æ¥ï¼Œå¯ä»¥å¯åŠ¨æœ¬åœ° Redis Stack æœåŠ¡å™¨ï¼š</font>

```bash
docker run -d -p 6379:6379 -p 8001:8001 redis/redis-stack:latest
```

```python
REDIS_URL = "redis://localhost:6379/0"
```



### <font style="color:rgb(28, 30, 33);">è°ƒç”¨èŠå¤©æ¥å£ï¼Œçœ‹Redisæ˜¯å¦å­˜å‚¨å†å²è®°å½•</font>
<font style="color:rgb(28, 30, 33);">æ›´æ–°æ¶ˆæ¯å†å²å®ç°åªéœ€è¦æˆ‘ä»¬å®šä¹‰ä¸€ä¸ªæ–°çš„å¯è°ƒç”¨å¯¹è±¡ï¼Œè¿™æ¬¡è¿”å›ä¸€ä¸ª </font>`<font style="color:rgb(28, 30, 33);">RedisChatMessageHistory</font>`<font style="color:rgb(28, 30, 33);"> å®ä¾‹ï¼š</font>

```python
from langchain_community.chat_message_histories import RedisChatMessageHistory
def get_message_history(session_id: str) -> RedisChatMessageHistory:
    return RedisChatMessageHistory(session_id, url=REDIS_URL)
with_message_history = RunnableWithMessageHistory(
    runnable,
    get_message_history,
    input_messages_key="input",
    history_messages_key="history",
)
```

<font style="color:rgb(28, 30, 33);">æˆ‘ä»¬å¯ä»¥åƒä»¥å‰ä¸€æ ·è°ƒç”¨ï¼š</font>

```python
with_message_history.invoke(
    {"ability": "math", "input": "ä½™å¼¦æ˜¯ä»€ä¹ˆæ„æ€ï¼Ÿ"},
    config={"configurable": {"session_id": "foobar"}},
)
```

```plain
content='ä½™å¼¦æ˜¯ä¸€ä¸ªä¸‰è§’å‡½æ•°ï¼Œå®ƒè¡¨ç¤ºç›´è§’ä¸‰è§’å½¢çš„é‚»è¾¹é•¿åº¦å’Œæ–œè¾¹é•¿åº¦çš„æ¯”å€¼ã€‚' response_metadata={'token_usage': {'completion_tokens': 33, 'prompt_tokens': 38, 'total_tokens': 71}, 'model_name': 'gpt-4-0613', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-2d1eba02-4709-4db5-ab6b-0fd03ab4c68a-0' usage_metadata={'input_tokens': 38, 'output_tokens': 33, 'total_tokens': 71}
```

```python
with_message_history.invoke(
    {"ability": "math", "input": "ä»€ä¹ˆ?"},
    config={"configurable": {"session_id": "foobar"}},
)
```

```plain
content='ä½™å¼¦æ˜¯ä¸€ä¸ªæ•°å­¦æœ¯è¯­ï¼Œä»£è¡¨åœ¨ä¸€ä¸ªè§’åº¦ä¸‹çš„é‚»è¾¹å’Œæ–œè¾¹çš„æ¯”ä¾‹ã€‚' response_metadata={'token_usage': {'completion_tokens': 32, 'prompt_tokens': 83, 'total_tokens': 115}, 'model_name': 'gpt-4-0613', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-99368d03-c2ed-4dda-a32f-677c036ad676-0' usage_metadata={'input_tokens': 83, 'output_tokens': 32, 'total_tokens': 115}
```

rediså†å²è®°å½•æŸ¥è¯¢

![](https://cdn.nlark.com/yuque/0/2024/png/2424104/1722421493358-fed79174-96ba-4f32-809b-6c153c5513de.png)



# Track token usage, Cache model responses
## Track token usage(è·Ÿè¸ªtokenä½¿ç”¨æƒ…å†µ)
<font style="color:rgb(28, 30, 33);">è·Ÿè¸ªä»¤ç‰Œä½¿ç”¨æƒ…å†µä»¥è®¡ç®—æˆæœ¬æ˜¯å°†æ‚¨çš„åº”ç”¨æŠ•å…¥ç”Ÿäº§çš„é‡è¦éƒ¨åˆ†ã€‚æœ¬æŒ‡å—ä»‹ç»äº†å¦‚ä½•ä»æ‚¨çš„ LangChain æ¨¡å‹è°ƒç”¨ä¸­è·å–æ­¤ä¿¡æ¯ã€‚</font>

### <font style="color:rgb(28, 30, 33);">ä½¿ç”¨ AIMessage.response_metadata</font>
<font style="color:rgb(28, 30, 33);">è®¸å¤šæ¨¡å‹æä¾›ç¨‹åºå°†ä»¤ç‰Œä½¿ç”¨ä¿¡æ¯ä½œä¸ºèŠå¤©ç”Ÿæˆå“åº”çš„ä¸€éƒ¨åˆ†è¿”å›ã€‚å¦‚æœå¯ç”¨ï¼Œè¿™å°†åŒ…å«åœ¨</font><font style="color:rgb(28, 30, 33);"> </font>[<font style="color:rgb(28, 30, 33);">AIMessage.response_metadata</font>](http://www.aidoczh.com/langchain/v0.2/docs/how_to/response_metadata/)<font style="color:rgb(28, 30, 33);"> </font><font style="color:rgb(28, 30, 33);">å­—æ®µä¸­ã€‚ä»¥ä¸‹æ˜¯ä¸€ä¸ªä½¿ç”¨ OpenAI çš„ç¤ºä¾‹ï¼š</font>

```python
# !pip install -qU langchain-openai
from langchain_openai import ChatOpenAI
llm = ChatOpenAI(model="gpt-4-turbo")
msg = llm.invoke([("human", "æœ€å¤è€çš„æ¥”å½¢æ–‡å­—çš„å·²çŸ¥ä¾‹å­æ˜¯ä»€ä¹ˆ")])
msg.response_metadata
```

```python
{'token_usage': {'completion_tokens': 114, 'prompt_tokens': 25, 'total_tokens': 139}, 'model_name': 'gpt-4-0613', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}
```



### <font style="color:rgb(28, 30, 33);">ä½¿ç”¨å›è°ƒ</font>
<font style="color:rgb(28, 30, 33);">è¿˜æœ‰ä¸€äº›ç‰¹å®šäº API çš„å›è°ƒä¸Šä¸‹æ–‡ç®¡ç†å™¨ï¼Œå…è®¸æ‚¨è·Ÿè¸ªå¤šä¸ªè°ƒç”¨ä¸­çš„ä»¤ç‰Œä½¿ç”¨æƒ…å†µã€‚ç›®å‰ä»…ä¸º OpenAI API å’Œ Bedrock Anthropic API å®ç°äº†æ­¤åŠŸèƒ½ã€‚</font>

<font style="color:rgb(28, 30, 33);">è®©æˆ‘ä»¬é¦–å…ˆçœ‹ä¸€ä¸ªæå…¶ç®€å•çš„ç¤ºä¾‹ï¼Œç”¨äºè·Ÿè¸ªå•ä¸ª Chat æ¨¡å‹è°ƒç”¨çš„ä»¤ç‰Œä½¿ç”¨æƒ…å†µã€‚</font>

```python
# !pip install -qU langchain-community wikipedia
from langchain_community.callbacks.manager import get_openai_callback
llm = ChatOpenAI(model="gpt-4", temperature=0)
with get_openai_callback() as cb:
    result = llm.invoke("å‘Šè¯‰æˆ‘ä¸€ä¸ªç¬‘è¯")
    print(cb)
```

```plain
Tokens Used: 59
Prompt Tokens: 14
Completion Tokens: 45
Successful Requests: 1
Total Cost (USD): $0.0031199999999999995
----------------------------------------
ä½¿ç”¨çš„ä»¤ç‰Œæ•°ï¼š59
    æç¤ºä»¤ç‰Œï¼š14
    å®Œæˆä»¤ç‰Œï¼š4
æˆåŠŸè¯·æ±‚æ¬¡æ•°ï¼š1
æ€»æˆæœ¬ï¼ˆç¾å…ƒï¼‰ï¼š$0.0031199999999999995
```

<font style="color:rgb(28, 30, 33);">ä¸Šä¸‹æ–‡ç®¡ç†å™¨ä¸­çš„ä»»ä½•å†…å®¹éƒ½å°†è¢«è·Ÿè¸ªã€‚ä»¥ä¸‹æ˜¯åœ¨å…¶ä¸­ä½¿ç”¨å®ƒæ¥è·Ÿè¸ªè¿ç»­å¤šæ¬¡è°ƒç”¨çš„ç¤ºä¾‹ã€‚</font>

```python
with get_openai_callback() as cb:
    result = llm.invoke("å‘Šè¯‰æˆ‘ä¸€ä¸ªç¬‘è¯")
        result2 = llm.invoke("å‘Šè¯‰æˆ‘ä¸€ä¸ªç¬‘è¯")
    print(cb.total_tokens)
```

```plain
114
```

<font style="color:rgb(28, 30, 33);">å¦‚æœä½¿ç”¨å…·æœ‰å¤šä¸ªæ­¥éª¤çš„é“¾æˆ–ä»£ç†ï¼Œå®ƒå°†è·Ÿè¸ªæ‰€æœ‰è¿™äº›æ­¥éª¤ã€‚</font>

```python
from langchain.agents import AgentExecutor, create_tool_calling_agent, load_tools
from langchain_core.prompts import ChatPromptTemplate
prompt = ChatPromptTemplate.from_messages(
    [
        ("system", "æ‚¨æ˜¯ä¸€ä¸ªä¹äºåŠ©äººçš„åŠ©æ‰‹"),
        ("human", "{input}"),
        ("placeholder", "{agent_scratchpad}"),
    ]
)
tools = load_tools(["wikipedia"])
agent = create_tool_calling_agent(llm, tools, prompt)
agent_executor = AgentExecutor(
    agent=agent, tools=tools, verbose=True, stream_runnable=False
)
```

æˆ‘ä»¬å¿…é¡»å°† `stream_runnable=False` è®¾ç½®ä¸ºä»¤ç‰Œè®¡æ•°æ‰èƒ½æ­£å¸¸å·¥ä½œã€‚é»˜è®¤æƒ…å†µä¸‹ï¼ŒAgentExecutor å°†æµå¼ä¼ è¾“åº•å±‚ä»£ç†ï¼Œä»¥ä¾¿åœ¨é€šè¿‡ AgentExecutor.stream_events æµå¼ä¼ è¾“äº‹ä»¶æ—¶è·å¾—æœ€ç²¾ç»†çš„ç»“æœã€‚ä½†æ˜¯ï¼ŒOpenAI åœ¨æµå¼ä¼ è¾“æ¨¡å‹å“åº”æ—¶ä¸ä¼šè¿”å›ä»¤ç‰Œè®¡æ•°ï¼Œå› æ­¤æˆ‘ä»¬éœ€è¦å…³é—­åº•å±‚æµå¼ä¼ è¾“ã€‚

```python
with get_openai_callback() as cb:
    response = agent_executor.invoke(
        {
            "input": "èœ‚é¸Ÿçš„å­¦åæ˜¯ä»€ä¹ˆï¼Œå“ªç§é¸Ÿæ˜¯æœ€å¿«çš„ï¼Ÿ"
        }
    )
    print(f"æ€»ä»¤ç‰Œæ•°ï¼š{cb.total_tokens}")
    print(f"æç¤ºä»¤ç‰Œï¼š{cb.prompt_tokens}")
    print(f"å®Œæˆä»¤ç‰Œï¼š{cb.completion_tokens}")
    print(f"æ€»æˆæœ¬ï¼ˆç¾å…ƒï¼‰ï¼š${cb.total_cost}")
```

```plain
> Entering new AgentExecutor chain...

Invoking: `wikipedia` with `{'query': 'èœ‚é¸Ÿ'}`


Page: Hawick Lau
Summary: Hawick Lau Hoi-wai (Chinese: åŠ‰æ„·å¨; born 13 October 1974) is a Hong Kong actor and singer. He was named as one of the "Five Fresh Tigers of TVB" and is best known for his performances in the series A Kindred Spirit (1995), Virtues of Harmony (2001) and My Family (2005).
He then expanded his career into mainland China, acting in several notable series. His notable appearances include Sealed with a Kiss (2011), A Clear Midsummer Night (2013), The Wife's Secret (2014), Lady & Liar (2015) and Chronicle of Life (2016).

Page: Zhang Jianing
Summary: Zhang Jianing (Chinese: å¼ ä½³å®, born 26 May 1989), also known as Karlina Zhang, is a Chinese actress. She is best known for her roles as Muyun Yanshuang in Tribes and Empires: Storm of Prophecy (2017) and Lin Beixing in Shining for One Thing (2022).

Page: Li Xirui
Summary: Li Xirui (Chinese: ææºªèŠ®; born 30 January 1990) is a Chinese actress and singer.
Invoking: `wikipedia` with `{'query': 'èœ‚é¸Ÿå­¦å'}`


No good Wikipedia Search Result was found
Invoking: `wikipedia` with `{'query': 'fastest bird'}`


Page: Fastest animals
Summary: This is a list of the fastest animals in the world, by types of animal.

Page: List of birds by flight speed
Summary: This is a list of the fastest flying birds in the world. A bird's velocity is necessarily variable; a hunting bird will reach much greater speeds while diving to catch prey than when flying horizontally. The bird that can achieve the greatest airspeed is the peregrine falcon (Falco peregrinus), able to exceed 320 km/h (200 mph) in its dives. A close relative of the common swift, the white-throated needletail (Hirundapus caudacutus), is commonly reported as the fastest bird in level flight with a reported top speed of 169 km/h (105 mph). This record remains unconfirmed as the measurement methods have never been published or verified. The record for the fastest confirmed level flight by a bird is 111.5 km/h (69.3 mph) held by the common swift.

Page: Abdul Khaliq (athlete)
Summary: Subedar Abdul Khaliq (Punjabi, Urdu: Ø¹Ø¨Ø¯ Ø§Ù„Ø®Ø§Ù„Ù‚; 23 March 1933 â€“ 10 March 1988), also known as Parinda-e-Asia (Urdu for The Flying Bird of Asia), was a Pakistani sprinter from 8 Medium Regiment Artillery who won 36 international gold medals, 15 international silver medals, and 12 International bronze medals while representing Pakistan. He competed in the 100m, 200m, and 4 x 100 meters relay. He participated in the 1956 Melbourne Olympics and the 1960 Rome Olympics. He also participated in the 1954 Asian Games and the 1958 Asian Games. During the 1956 Indo-Pak Meet held in Delhi, Abdul Khaliq was first referred to as "The Flying Bird of Asia" by the Prime Minister of India of the time was Jawaharlal Nehru, who was reportedly captivated by his performance during the event.èœ‚é¸Ÿçš„å­¦åæ˜¯Trochilidaeã€‚æœ€å¿«çš„é¸Ÿæ˜¯æ¸¸éš¼ï¼ˆFalco peregrinusï¼‰ï¼Œåœ¨ä¿¯å†²æ•é£Ÿæ—¶ï¼Œé€Ÿåº¦å¯ä»¥è¶…è¿‡320å…¬é‡Œ/å°æ—¶ï¼ˆ200è‹±é‡Œ/å°æ—¶ï¼‰ã€‚åœ¨æ°´å¹³é£è¡Œä¸­ï¼Œæœ€å¿«çš„é¸Ÿæ˜¯æ™®é€šé›¨ç‡•ï¼Œå…¶ç¡®è®¤çš„æœ€é«˜é€Ÿåº¦ä¸º111.5å…¬é‡Œ/å°æ—¶ï¼ˆ69.3è‹±é‡Œ/å°æ—¶ï¼‰ã€‚

> Finished chain.
æ€»ä»¤ç‰Œæ•°ï¼š2088
æç¤ºä»¤ç‰Œï¼š1922
å®Œæˆä»¤ç‰Œï¼š166
æ€»æˆæœ¬ï¼ˆç¾å…ƒï¼‰ï¼š$0.06762
```



## Cache model responses
<font style="color:rgb(28, 30, 33);"> LangChainä¸ºèŠå¤©æ¨¡å‹æä¾›äº†ä¸€ä¸ªå¯é€‰çš„ç¼“å­˜å±‚ã€‚è¿™å¾ˆæœ‰ç”¨ï¼Œä¸»è¦æœ‰ä¸¤ä¸ªåŸå› ï¼š</font>

+ <font style="color:rgb(28, 30, 33);"></font><font style="color:rgb(28, 30, 33);">å¦‚æœæ‚¨ç»å¸¸å¤šæ¬¡è¯·æ±‚ç›¸åŒçš„å®Œæˆï¼Œå®ƒå¯ä»¥é€šè¿‡å‡å°‘æ‚¨å‘ LLM æä¾›å•†è¿›è¡Œçš„ API è°ƒç”¨æ¬¡æ•°æ¥ä¸ºæ‚¨èŠ‚çœèµ„é‡‘ã€‚è¿™åœ¨åº”ç”¨ç¨‹åºå¼€å‘è¿‡ç¨‹ä¸­ç‰¹åˆ«æœ‰ç”¨ã€‚</font>
+ <font style="color:rgb(28, 30, 33);">å®ƒå¯ä»¥é€šè¿‡å‡å°‘æ‚¨å‘ LLM æä¾›å•†è¿›è¡Œçš„ API è°ƒç”¨æ¬¡æ•°æ¥åŠ å¿«æ‚¨çš„åº”ç”¨ç¨‹åºã€‚</font>

```bash
pip install -qU langchain-openai
```

```python
from langchain_openai import ChatOpenAI
llm = ChatOpenAI(model="gpt-4o")
```

```python
from langchain.globals import set_llm_cache
```

**API Reference: **[set_llm_cache](https://api.python.langchain.com/en/latest/globals/langchain.globals.set_llm_cache.html)

### <font style="color:rgb(28, 30, 33);">In Memory Cache å†…å­˜ç¼“å­˜ä¸­</font>
<font style="color:rgb(28, 30, 33);">This is an ephemeral cache that stores model calls in memory. It will be wiped when your environment restarts, and is not shared across processes.  
</font><font style="color:rgb(28, 30, 33);">è¿™æ˜¯ä¸€ä¸ªä¸´æ—¶ç¼“å­˜ï¼Œç”¨äºåœ¨å†…å­˜ä¸­å­˜å‚¨æ¨¡å‹è°ƒç”¨ã€‚å½“æ‚¨çš„ç¯å¢ƒé‡æ–°å¯åŠ¨æ—¶ï¼Œå®ƒå°†è¢«æ“¦é™¤ï¼Œå¹¶ä¸”ä¸ä¼šåœ¨è¿›ç¨‹ä¹‹é—´å…±äº«ã€‚</font>

```python
from langchain.globals import set_llm_cache
from langchain_community.cache import InMemoryCache

# åˆ›å»ºLLMå®ä¾‹
llm = ChatOpenAI(model="gpt-4")
set_llm_cache(InMemoryCache())

def measure_invoke_time(llm, prompt):
    # è®°å½•å¼€å§‹æ—¶é—´
    start_wall_time = time.time()
    start_cpu_times = os.times()

    # è°ƒç”¨LLM
    response = llm.invoke(prompt)

    # è®°å½•ç»“æŸæ—¶é—´
    end_wall_time = time.time()
    end_cpu_times = os.times()

    # è®¡ç®—ç»è¿‡çš„æ—¶é—´
    wall_time = end_wall_time - start_wall_time
    user_time = end_cpu_times.user - start_cpu_times.user
    sys_time = end_cpu_times.system - start_cpu_times.system
    total_cpu_time = user_time + sys_time
    return response, wall_time, user_time, sys_time, total_cpu_time

```

**API Reference: **[InMemoryCache](https://api.python.langchain.com/en/latest/cache/langchain_community.cache.InMemoryCache.html)



```plain
# ç¬¬ä¸€æ¬¡è°ƒç”¨
First call response: content='å½“ç„¶ï¼Œè¿™æ˜¯ä¸€åˆ™å…³äºæ•°å­¦çš„ç¬‘è¯ï¼š\n\nä¸ºä»€ä¹ˆæ¤ç‰©æ¨æ•°å­¦ï¼Ÿ\n\nå› ä¸ºå®ƒç»™ä»–ä»¬å¤ªå¤šçš„æ ¹é—®é¢˜ï¼ˆsqrté—®é¢˜ï¼‰ã€‚' response_metadata={'token_usage': {'completion_tokens': 46, 'prompt_tokens': 14, 'total_tokens': 60}, 'model_name': 'gpt-4-0613', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-40d86131-39ad-42c9-b3b8-5a422343ba9b-0' usage_metadata={'input_tokens': 14, 'output_tokens': 46, 'total_tokens': 60}
First call CPU times: user 109 ms, sys: 31 ms, total: 141 ms
First call Wall time: 3654 ms
```

```plain
content='å½“ç„¶ï¼Œè¿™æ˜¯ä¸€åˆ™å…³äºæ•°å­¦çš„ç¬‘è¯ï¼š\n\nä¸ºä»€ä¹ˆæ¤ç‰©æ¨æ•°å­¦ï¼Ÿ\n\nå› ä¸ºå®ƒç»™ä»–ä»¬å¤ªå¤šçš„æ ¹é—®é¢˜ï¼ˆsqrté—®é¢˜ï¼‰ã€‚'
```

```python
#ç¬¬äºŒæ¬¡è°ƒç”¨ä½¿ç”¨ç¼“å­˜ï¼Œæ‰€ä»¥é€Ÿåº¦å¾ˆå¿«
response2, wall_time2, user_time2, sys_time2, total_cpu_time2 = measure_invoke_time(llm, "ç»™æˆ‘è®²ä¸ªç¬‘è¯")
print("Second call response:", response2)
print(f"Second call CPU times: user {user_time2 * 1000:.0f} ms, sys: {sys_time2 * 1000:.0f} ms, total: {total_cpu_time2 * 1000:.0f} ms")
print(f"Second call Wall time: {wall_time2 * 1000:.0f} ms")
```

```plain
Second call response: content='å½“ç„¶ï¼Œè¿™æ˜¯ä¸€åˆ™å…³äºæ•°å­¦çš„ç¬‘è¯ï¼š\n\nä¸ºä»€ä¹ˆæ¤ç‰©æ¨æ•°å­¦ï¼Ÿ\n\nå› ä¸ºå®ƒç»™ä»–ä»¬å¤ªå¤šçš„æ ¹é—®é¢˜ï¼ˆsqrté—®é¢˜ï¼‰ã€‚' response_metadata={'token_usage': {'completion_tokens': 46, 'prompt_tokens': 14, 'total_tokens': 60}, 'model_name': 'gpt-4-0613', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-40d86131-39ad-42c9-b3b8-5a422343ba9b-0' usage_metadata={'input_tokens': 14, 'output_tokens': 46, 'total_tokens': 60}
Second call CPU times: user 16 ms, sys: 0 ms, total: 16 ms
Second call Wall time: 1 ms
```

```plain
content='å½“ç„¶ï¼Œè¿™æ˜¯ä¸€åˆ™å…³äºæ•°å­¦çš„ç¬‘è¯ï¼š\n\nä¸ºä»€ä¹ˆæ¤ç‰©æ¨æ•°å­¦ï¼Ÿ\n\nå› ä¸ºå®ƒç»™ä»–ä»¬å¤ªå¤šçš„æ ¹é—®é¢˜ï¼ˆsqrté—®é¢˜ï¼‰ã€‚'
```

### <font style="color:rgb(28, 30, 33);">SQLite Cache SQLite ç¼“å­˜</font>
<font style="color:rgb(28, 30, 33);">This cache implementation uses a </font>`<font style="color:rgb(28, 30, 33);">SQLite</font>`<font style="color:rgb(28, 30, 33);"> database to store responses, and will last across process restarts.  
</font><font style="color:rgb(28, 30, 33);">æ­¤ç¼“å­˜å®ç°ä½¿ç”¨ </font>`<font style="color:rgb(28, 30, 33);">SQLite</font>`<font style="color:rgb(28, 30, 33);"> æ•°æ®åº“æ¥å­˜å‚¨å“åº”ï¼Œå¹¶å°†åœ¨è¿›ç¨‹é‡å¯åæŒç»­è¿›è¡Œã€‚</font>

```python
# We can do the same thing with a SQLite cache
from langchain_community.cache import SQLiteCache
set_llm_cache(SQLiteCache(database_path=".langchain.db"))
```

**API Reference: **[SQLiteCache](https://api.python.langchain.com/en/latest/cache/langchain_community.cache.SQLiteCache.html)

```plain
# ç¬¬ä¸€æ¬¡è°ƒç”¨
First call response: content='å½“ç„¶ï¼Œè¿™æ˜¯ä¸€åˆ™å…³äºæ•°å­¦çš„ç¬‘è¯ï¼š\n\nä¸ºä»€ä¹ˆæ¤ç‰©æ¨æ•°å­¦ï¼Ÿ\n\nå› ä¸ºå®ƒç»™ä»–ä»¬å¤ªå¤šçš„æ ¹é—®é¢˜ï¼ˆsqrté—®é¢˜ï¼‰ã€‚' response_metadata={'token_usage': {'completion_tokens': 46, 'prompt_tokens': 14, 'total_tokens': 60}, 'model_name': 'gpt-4-0613', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-40d86131-39ad-42c9-b3b8-5a422343ba9b-0' usage_metadata={'input_tokens': 14, 'output_tokens': 46, 'total_tokens': 60}
First call CPU times: user 109 ms, sys: 31 ms, total: 141 ms
First call Wall time: 3654 ms
```

```plain
content='å¥½çš„ï¼Œè¿™æ˜¯ä¸€ä¸ªå…³äºç”µè„‘çš„ç¬‘è¯ï¼š\n\nä¸ºä»€ä¹ˆç”µè„‘ç»å¸¸æ„Ÿå†’ï¼Ÿ\n\nå› ä¸ºå®ƒçª—æˆ·(Window)å¤ªå¤šäº†ã€‚'
```

```python
#ç¬¬äºŒæ¬¡è°ƒç”¨ä½¿ç”¨ç¼“å­˜ï¼Œæ‰€ä»¥é€Ÿåº¦å¾ˆå¿«
response2, wall_time2, user_time2, sys_time2, total_cpu_time2 = measure_invoke_time(llm, "ç»™æˆ‘è®²ä¸ªç¬‘è¯")
print("Second call response:", response2)
print(f"Second call CPU times: user {user_time2 * 1000:.0f} ms, sys: {sys_time2 * 1000:.0f} ms, total: {total_cpu_time2 * 1000:.0f} ms")
print(f"Second call Wall time: {wall_time2 * 1000:.0f} ms")
```

```plain
Second call response: content='å½“ç„¶ï¼Œè¿™æ˜¯ä¸€åˆ™å…³äºæ•°å­¦çš„ç¬‘è¯ï¼š\n\nä¸ºä»€ä¹ˆæ¤ç‰©æ¨æ•°å­¦ï¼Ÿ\n\nå› ä¸ºå®ƒç»™ä»–ä»¬å¤ªå¤šçš„æ ¹é—®é¢˜ï¼ˆsqrté—®é¢˜ï¼‰ã€‚' response_metadata={'token_usage': {'completion_tokens': 46, 'prompt_tokens': 14, 'total_tokens': 60}, 'model_name': 'gpt-4-0613', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-40d86131-39ad-42c9-b3b8-5a422343ba9b-0' usage_metadata={'input_tokens': 14, 'output_tokens': 46, 'total_tokens': 60}
Second call CPU times: user 16 ms, sys: 0 ms, total: 16 ms
Second call Wall time: 1 ms
```

```plain
content='å¥½çš„ï¼Œè¿™æ˜¯ä¸€ä¸ªå…³äºç”µè„‘çš„ç¬‘è¯ï¼š\n\nä¸ºä»€ä¹ˆç”µè„‘ç»å¸¸æ„Ÿå†’ï¼Ÿ\n\nå› ä¸ºå®ƒçª—æˆ·(Window)å¤ªå¤šäº†ã€‚'
```

